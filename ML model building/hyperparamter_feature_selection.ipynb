{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ncGoh96_PNuz"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import copy\n","import shap\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import optuna\n","from optuna.samplers import TPESampler\n","from optuna.trial import Trial\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.feature_selection import RFECV\n","from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler, RobustScaler\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.model_selection import GridSearchCV, train_test_split, KFold, LeaveOneOut, StratifiedKFold, cross_val_score\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","from sklearn.utils import shuffle\n","from sklearn.base import clone\n","from sklearn import preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dc4_EgYuPNu2"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWF9oXvoPNu3"},"outputs":[],"source":["filename = './머신러닝데이터.xlsx'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WKM54cTOPNu3"},"outputs":[],"source":["# Imputation한 데이터를 불러온다\n","scoring_transition_1 = pd.read_excel(filename, sheet_name='scoring_result_merged', engine='openpyxl')\n","scoring_transition_0 = pd.read_excel(filename, sheet_name='scoring_origin', engine='openpyxl')\n","task_completion_time = pd.read_excel(filename, sheet_name='task_completion_time_mean_imput', engine='openpyxl')\n","sms_reply = pd.read_excel(filename, sheet_name='SMS_reply', engine='openpyxl')\n","weather_searching_site_region = pd.read_excel(filename, sheet_name='weather_searching_사이트주소', engine='openpyxl')"]},{"cell_type":"markdown","metadata":{"id":"cBYtw1aaPNu4"},"source":["# 모든 Feature List\n","sms_reply, weather_searching_사이트주소는 feature 리스트가 같습니다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JNGQtC3NPNu5"},"outputs":[],"source":["# scoring = ['Routine_Screen_Unlock_Pattern', 'Routine_Phone_Register', 'Routine_Phone_Receive', 'Routine_SMS_Reply', 'Routine_Camera', \n","# 'Routine_Location_Searching', 'Routine_Weather_Searching', 'Routine_Transfer', 'Routine_Location_Switching', 'Routine_Weather_Switching', \n","# 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', 'Transition_Camera', 'Transition_Location_Searching', \n","# 'Transition_Weather_Searching', 'Transition_Transfer', 'Transition_Location_Switching', 'Transition_Weather_Switching', 'Result_Phone_Register', \n","# 'Result_Phone_Receive', 'Result_SMS_Reply', 'Result_Camera', 'Result_Location_Searching', 'Result_Weather_Searching', 'Result_Transfer', \n","# 'Result_Location_Switching', 'Result_Weather_Switching', 'routine_sum_trial', 'transition_sum_trial', 'result_sum_trial', 'all_sum_trial']\n","\n","# task = ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_total_time_nt', \n","# 'phone_register_screen_unlocking_time', 'phone_register_sms_start_time', 'phone_register_instruction_check_time', 'phone_register_total_time', \n","# 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_noti response', 'phone_receive_total_time_nt', 'phone_receive_total_time', \n","# 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_noti_response_time', 'sms_reply_total_time_nt', 'sms_reply_compeltion_time', \n","# 'sms_reply_total_time', 'camera_noti_response', 'camera_total_time_nt', 'camera_instruction_check_time', 'camera_total_time', 'camera_taken_time', \n","# 'camera_gallery_delete_time', 'transfer_noti_response_time', 'transfer_total_time_nt', 'transfer_instruction_check_time', 'transfer_total_time', \n","# 'transfer_usage_time', 'transfer_share_time', 'weather_searching_noti_response', 'weather_searching_total_time_nt', 'weather_searching_instruction_check_time', \n","# 'weather_searching_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_switching_notification_response_time', \n","# 'weather_switching_total_time_nt', 'weather_switching_instruction_check_time', 'weather_switching_total_time', \n","# 'weather_switching_first_searching_keyword_typing_time', 'weather_switching_second_searching_keyword_typing_time', \n","# 'weather_switching_information_searching_time', 'weather_switching_information_sharing_texting_time', 'location_searching_noti_response_time', \n","# 'location_searching_total_time_nt', 'location_searching_instruction_check_time', 'location_searching_total_time', 'location_searching_food_typing_time', \n","# 'location_searching_foodtyping_mapfinding_time', 'location_searching_mapfinding_time', 'location_searching_route_sharing_texting_time', \n","# 'location_switching_notification_response', 'location_switching_total_time_nt', 'location_switching_instruction_check', 'location_switching_total_time', \n","# 'location_switching_first_map_typing_time', 'location_switching_second_map_typing_time', 'location_switching_map_finding_time', \n","# 'location_switching_map_route_sharing_time']\n","\n","# sms_and_ws = ['average intercharacter time', 'std intercharacter time', 'median intercharacter time', 'min intercharacter time', 'max intercharacter time', \n","# 'total_time (S)', 'total_count', 'IS (C+IF+INF+F)', 'backspace (F)', 'C', 'IF', 'INF', 'Shift', 'ISø (IS+S)', 'T (total_count-F)', 'WPS', 'WPM', 'AdjWPS', \n","# 'AdjWPM', 'CPS', 'KSPS', 'GPS', 'KSPC', 'GPC', 'MSD', 'COER', 'UER', 'TER', 'CE', 'PC', 'UB', 'WB', 'CPC']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XN87EAkPNu7"},"outputs":[],"source":["# BAC column만 가져온다(Label)\n","y = scoring_transition_1['BAC']\n","\n","# Participant, BAC column을 제거한다\n","scoring_transition_1 = scoring_transition_1.drop(['Participant', 'BAC'], axis=1)\n","scoring_transition_0 = scoring_transition_0.drop(['Participant', 'BAC'], axis=1)\n","task_completion_time = task_completion_time.drop(['Participant', 'BAC'], axis=1)\n","sms_reply = sms_reply.drop(['Participant', 'BAC'], axis=1)\n","weather_searching_site_region = weather_searching_site_region.drop(['Participant', 'BAC'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFLbArUTPNu7"},"outputs":[],"source":["# 라벨 3개용 features\n","# 각 데이터별로 필요한 column들만 뽑는다\n","scoring_transition_1_columns = ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', \n","'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial']\n","\n","scoring_transition_0_columns = []\n","\n","task_completion_time_columns = ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', \n","'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', \n","'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', \n","'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', \n","'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time']\n","\n","sms_reply_columns = ['average intercharacter time', 'median intercharacter time', 'min intercharacter time', 'max intercharacter time', \n","'CPS', 'KSPS', 'GPS', 'COER', 'UER', 'TER', 'UB', 'WB']\n","\n","weather_searching_site_region_columns = ['average intercharacter time', 'median intercharacter time', 'min intercharacter time', 'max intercharacter time', \n","'CPS', 'KSPS', 'COER', 'UB', 'WB']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fNAInN10PNu8"},"outputs":[],"source":["# 라벨을 2개용 features\n","scoring_transition_1_columns_two_label = ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', \n","'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial']\n","\n","scoring_transition_0_columns_two_label = []\n","\n","task_completion_time_columns_two_label = ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', \n","'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', \n","'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', \n","'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', \n","'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time']\n","\n","sms_reply_columns_two_label = ['average intercharacter time', 'median intercharacter time', 'min intercharacter time', 'max intercharacter time', \n","'CPS', 'KSPS', 'GPS', 'COER', 'UER', 'TER', 'UB', 'WB']\n","\n","weather_searching_site_region_columns_two_label = ['average intercharacter time', 'median intercharacter time', 'min intercharacter time', 'max intercharacter time', \n","'CPS', 'KSPS', 'COER', 'UB', 'WB']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jeTPa2wFPNu8"},"outputs":[],"source":["# 위에서 정한 feature들로 각각의 데이터 프레임을 생성한다\n","scoring_transition_1_df = scoring_transition_1[scoring_transition_1_columns]\n","scoring_transition_0_df = scoring_transition_0[scoring_transition_0_columns]\n","task_completion_time_df = task_completion_time[task_completion_time_columns]\n","sms_reply_df = sms_reply[sms_reply_columns]\n","weather_searching_site_region_df = weather_searching_site_region[weather_searching_site_region_columns]\n","\n","scoring_transition_1_df_two_label = scoring_transition_1[scoring_transition_1_columns_two_label]\n","scoring_transition_0_df_two_label = scoring_transition_0[scoring_transition_0_columns_two_label]\n","task_completion_time_df_two_label = task_completion_time[task_completion_time_columns_two_label]\n","sms_reply_df_two_label = sms_reply[sms_reply_columns_two_label]\n","weather_searching_site_region_df_two_label = weather_searching_site_region[weather_searching_site_region_columns_two_label]"]},{"cell_type":"markdown","metadata":{"id":"vJtuo9ZvPNu9"},"source":["# feature명 수정하기\n","위에서 적은 feature명을 그대로 복사해서 가져온 다음 바꾸려는 feature만 수정하면 됩니다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_-rD_1FPNu9"},"outputs":[],"source":["# 라벨 3개용 features의 feature명을 수정한다!\n","scoring_transition_1_columns = ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', \n","'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial']\n","\n","scoring_transition_0_columns = []\n","\n","task_completion_time_columns = ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', \n","'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', \n","'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', \n","'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', \n","'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time']\n","\n","sms_reply_columns = ['average intercharacter time', 'median intercharacter time', 'min intercharacter time', 'max intercharacter time', \n","'CPS', 'KSPS', 'GPS', 'COER', 'UER', 'TER', 'UB', 'WB']\n","\n","weather_searching_site_region_columns = ['average intercharacter time', 'median intercharacter time', 'min intercharacter time', 'max intercharacter time', \n","'CPS', 'KSPS', 'COER', 'UB', 'WB']\n","\n","scoring_transition_1_df.columns = scoring_transition_1_columns\n","scoring_transition_0_df.columns = scoring_transition_0_columns\n","task_completion_time_df.columns = task_completion_time_columns\n","sms_reply_df.columns = sms_reply_columns\n","weather_searching_site_region_df.columns = weather_searching_site_region_columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-7Z3UX2PNu9"},"outputs":[],"source":["# 라벨을 2개용 features의 feature명을 수정한다!\n","scoring_transition_1_columns_two_label = ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', \n","'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial']\n","\n","scoring_transition_0_columns_two_label = []\n","\n","task_completion_time_columns_two_label = ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', \n","'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', \n","'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', \n","'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', \n","'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time']\n","\n","sms_reply_columns_two_label = ['average intercharacter time', 'median intercharacter time', 'min intercharacter time', 'max intercharacter time', \n","'CPS', 'KSPS', 'GPS', 'COER', 'UER', 'TER', 'UB', 'WB']\n","\n","weather_searching_site_region_columns_two_label = ['average intercharacter time', 'median intercharacter time', 'min intercharacter time', 'max intercharacter time', \n","'CPS', 'KSPS', 'COER', 'UB', 'WB']\n","\n","scoring_transition_1_df_two_label.columns = scoring_transition_1_columns_two_label\n","scoring_transition_0_df_two_label.columns = scoring_transition_0_columns_two_label\n","task_completion_time_df_two_label.columns = task_completion_time_columns_two_label\n","sms_reply_df_two_label.columns = sms_reply_columns_two_label\n","weather_searching_site_region_df_two_label.columns = weather_searching_site_region_columns_two_label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JL61eqG5PNu-"},"outputs":[],"source":["# sms reply와 weather searching 사이트 주소의 feature명이 똑같으므로 feature명을 수정한다\n","sms_reply_df_columns = ['sms_' + col_name for col_name in sms_reply_df.columns] # sms reply feature 이름 앞에 sms_를 붙인다\n","weather_searching_site_region_df_columns = ['ws_' + col_name for col_name in weather_searching_site_region_df.columns] # ws feature 이름 앞에 ws_를 붙인다\n","\n","sms_reply_df.columns = sms_reply_df_columns # 수정된 sms reply feature명을 적용한다\n","weather_searching_site_region_df.columns = weather_searching_site_region_df_columns # 수정된 ws feature명을 적용한다\n","\n","# 위와 동일하게 작동한다\n","sms_reply_df_two_label_columns = ['sms_' + col_name for col_name in sms_reply_df_two_label.columns]\n","weather_searching_site_region_df_two_label_columns = ['ws_' + col_name for col_name in weather_searching_site_region_df_two_label.columns]\n","\n","sms_reply_df_two_label.columns = sms_reply_df_two_label_columns\n","weather_searching_site_region_df_two_label.columns = weather_searching_site_region_df_two_label_columns"]},{"cell_type":"markdown","metadata":{"id":"DA7XZyj4PNu-"},"source":["### merged_df : Label 3개인 데이터 집합\n","### merged_df_two_label : Label 2개인 데이터 집합"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"koxFzShePNu-"},"outputs":[],"source":["# 필요한 데이터 프레임들을 합친다\n","merged_df_list = [scoring_transition_1_df, scoring_transition_0_df, task_completion_time_df, sms_reply_df, weather_searching_site_region_df]\n","merged_df_list_two_label = [scoring_transition_1_df_two_label, scoring_transition_0_df_two_label, task_completion_time_df_two_label, \n","sms_reply_df_two_label, weather_searching_site_region_df_two_label]\n","\n","merged_df = pd.concat(merged_df_list, axis=1)\n","merged_df_two_label = pd.concat(merged_df_list_two_label, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kllWnNixPNu_"},"outputs":[],"source":["# Categorical 데이터에 대해서 인코딩한다\n","# 어떤 데이터가 Categorical 데이터인가?\n","\n","# 라벨에 대해서 인코딩한다\n","encoder = preprocessing.LabelEncoder()\n","y = encoder.fit_transform(y)"]},{"cell_type":"markdown","metadata":{"id":"EbDIF5_1PNu_"},"source":["### N : 3개 라벨에 대한 feature 개수 / M : 2개 라벨에 대한 feature 개수\n","merged_df.shape = (360, N), y.shape = (360, 1), 라벨 수: 3 </br>\n","merged_df_two_label.shape = (360, M), changed_label.shape = (360, 1), 라벨 수: 2 </br>\n","changed_df.shape = (240, M), changed_y.shape = (240, 1), 라벨 수: 2 </br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oojkT0oSPNu_"},"outputs":[],"source":["# 라벨에 대해서 인코딩한다(0 -> 0, 0.06 -> 1, 0.09 -> 2)\n","encoder = preprocessing.LabelEncoder()\n","y = encoder.fit_transform(y)\n","\n","# 3개의 라벨을 2개의 라벨로 바꾼다\n","changed_label = copy.deepcopy(y)\n","\n","for i in range(len(changed_label)):\n","    if changed_label[i] == 1:\n","        changed_label[i] = 0\n","\n","for i in range(len(changed_label)):\n","    if changed_label[i] == 2:\n","        changed_label[i] = 1\n","\n","# 라벨 0과 라벨 0.06의 평균을 구해서 하나의 라벨로 만든다\n","temp_y = pd.Series(y, name='Label')\n","temp_df = pd.concat([temp_y, merged_df_two_label], axis=1)\n","\n","changed_df = pd.DataFrame(columns=temp_df.columns)\n","\n","num = 0\n","for row_idx in range(0, len(temp_df), 9):\n","    for i in range(3):\n","        changed_df.loc[num] = (temp_df.loc[row_idx + i] + temp_df.loc[row_idx + i + 3])/2\n","        num += 1\n","    for i in range(3):\n","        changed_df.loc[num] = temp_df.loc[row_idx + 6 + i]\n","        num += 1\n","\n","changed_y = changed_df['Label']\n","changed_df = changed_df.drop(['Label'], axis=1)\n","changed_y = encoder.fit_transform(changed_y)\n","\n","# 3 Labels, 2 Labels(just change), 2 Labels(average)에 대한 데이터\n","label_processing = ['3 Labels', '2 Labels(just change)', '2 Labels(average)']\n","data_list = [(merged_df, y), (merged_df_two_label, changed_label), (changed_df, changed_y)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SShVj3kkPNvA"},"outputs":[],"source":["scaler_list = {\n","    'minmax': MinMaxScaler(),\n","    'maxabs': MaxAbsScaler(),\n","    'standard': StandardScaler(),\n","    'robust': RobustScaler()\n","}\n","\n","label_list = {\n","    'three_label': data_list[0],\n","    'two_label_changed': data_list[1],\n","    'two_label_average': data_list[2]\n","}\n","\n","# scaler_name과 label_name을 인자로 받아서 해당하는 X, y를 반환한다\n","def getXy(scaler_name, label_name):\n","    if scaler_name not in scaler_list.keys() and scaler_name != 'no_scale':\n","        raise ValueError(\"scaler_name must be 'minmax' or 'maxabs' or 'standard' or 'robust' or 'no_scale!\")\n","\n","    if label_name not in label_list.keys():\n","        raise ValueError(\"label_name must be 'three_label' or 'two_label_changed' or 'two_label_average'!\")\n","\n","    X, y = label_list[label_name]\n","\n","    if scaler_name != 'no_scale':\n","        scaler = scaler_list[scaler_name]\n","        df = X.copy()\n","\n","        df[df.columns] = scaler.fit_transform(df[df.columns])\n","\n","        X = df\n","        X[X.columns] = scaler.fit_transform(X[X.columns])\n","    \n","    return (X, y)"]},{"cell_type":"markdown","metadata":{"id":"u_TPCQK8PNvA"},"source":["# 어떤 label의 데이터로 돌릴 것인지, 어떤 scaler를 적용할 것인지, inner loop에서 어떤 cv 방법을 적용할 것인지, Stratified K-fold의 K를 정한다"]},{"cell_type":"markdown","metadata":{"id":"wUIhxUmPPNvA"},"source":["### scaler_name = 'minmax' or 'maxabs' or 'standard' or 'robust' or 'no_scale'\n","### label_name = 'three_label' or 'two_label_changed' or 'two_label_average'\n","### cv_method = 'loso' or 'k_fold'\n","### n_fold = 39(default)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwz-JY3TPNvA"},"outputs":[],"source":["scaler_name = 'no_scale'\n","label_name = 'two_label_changed'\n","cv_method = 'k_fold'\n","n_fold = 39\n","\n","X, y = getXy(scaler_name=scaler_name, label_name=label_name)"]},{"cell_type":"markdown","metadata":{"id":"GBlZmYFsPNvB"},"source":["# Optuna의 반복 수를 설정한다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7yVlvSNPNvB"},"outputs":[],"source":["n_trials = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGxbfPe-PNvB"},"outputs":[],"source":["def NestedCVwithOptuna(objective, clf, clf_name):\n","    metric_df = pd.DataFrame(columns=['model', 'accuracy', 'precision', 'recall', 'f1_score', 'roc_auc_score'])\n","    hyper_df_list = []\n","    feature_df_list = []\n","\n","    # 클래스가 몇 개인지 확인한다\n","    class_nums = len(set(y))\n","    print('class_nums : ', class_nums)\n","    n_splits = 40\n","    kfold = KFold(n_splits=n_splits)\n","\n","    mean_accuracy = 0\n","    mean_precision = 0\n","    mean_recall = 0\n","    mean_f1 = 0\n","    mean_roc_auc = 0\n","    \n","    list_shap_values = list()\n","    list_test_sets = list()\n","    \n","    shap_df_list = [[], [], []]\n","\n","    for num, (train_idx, val_idx) in enumerate(kfold.split(X)):\n","        X_train, X_val = X.iloc[train_idx, :], X.iloc[val_idx, :]\n","        y_train, y_val = y[train_idx], y[val_idx]\n","        \n","        classifier = clone(clf)\n","\n","        # Feature Selection을 진행한다\n","        selector = RFECV(classifier, step=2, cv=KFold(n_splits=3), min_features_to_select=20)\n","        selector = selector.fit(X_train, y_train)\n","\n","        columns = X_train.columns\n","        selected_list = selector.support_\n","\n","        selected_features = [col_name for i, col_name in enumerate(columns) if selected_list[i]]\n","\n","        # 뽑힌 feature들로 데이터를 만든다\n","        X_train = X_train[selected_features]\n","        X_val = X_val[selected_features]\n","\n","        # Bayesian Optimization을 진행한다\n","        sampler = TPESampler()\n","\n","        study = optuna.create_study(direction='maximize', sampler=sampler, study_name=f'{clf_name} Study')\n","        study.optimize(objective(X_train, y_train), n_trials=n_trials)\n","\n","        best_params = study.best_params\n","        print('Optuna Best score : ', study.best_value)\n","        print('Best parameters : ', best_params)\n","        print('Selected features Num: ', len(selected_features))\n","        print('Selected features : ', selected_features)\n","\n","        # Best feature를 저장하는 데이터 프레임을 생성한다\n","        feature_df = pd.DataFrame([selected_features])\n","        feature_df_list.append(feature_df)\n","\n","        # 하이퍼 파라미터를 저장하는 데이터 프레임을 생성한다\n","        hyper_df = pd.DataFrame([list(best_params.values())], columns=list(best_params.keys()))\n","        hyper_df_list.append(hyper_df)\n","\n","        if clf_name == 'lightgbm':\n","            best_clf = LGBMClassifier(**best_params, random_state=42)\n","        elif clf_name == 'xgboost':\n","            best_clf = XGBClassifier(**best_params, random_state=42)\n","        elif clf_name == 'randomforest':\n","            best_clf = RandomForestClassifier(**best_params, random_state=42)\n","        elif clf_name == 'gbm':\n","            best_clf = GradientBoostingClassifier(**best_params, random_state=42)\n","        \n","        best_clf.fit(X_train, y_train)\n","\n","        y_pred = best_clf.predict(X_val)\n","        y_pred_prob = best_clf.predict_proba(X_val)\n","\n","        # 개별 performance metric을 구한다\n","        accuracy = accuracy_score(y_val, y_pred)\n","        precision = precision_score(y_val, y_pred, average='macro')\n","        recall = recall_score(y_val, y_pred, average='macro')\n","        f1 = f1_score(y_val, y_pred, average='macro')\n","        if class_nums > 2:\n","            roc_auc = roc_auc_score(y_val, y_pred_prob, average='macro', multi_class='ovr')\n","        else:\n","            roc_auc = roc_auc_score(y_val, y_pred)\n","        \n","        # 개별 performance metric을 데이터 프레임으로 저장한다\n","        metric_df.loc[len(metric_df)] = [f'model_{num+1}', accuracy, precision, recall, f1, roc_auc]\n","\n","        # 평균 performance metric을 구한다\n","        mean_accuracy += accuracy / n_splits\n","        mean_precision += accuracy / n_splits\n","        mean_recall += recall / n_splits\n","        mean_f1 += f1 / n_splits\n","        mean_roc_auc += roc_auc / n_splits\n","\n","        print('test accuracy : ', accuracy)\n","\n","        # explaining model\n","        explainer = shap.TreeExplainer(best_clf)\n","        shap_values = explainer.shap_values(X_val)\n","        \n","        if class_nums > 2:\n","            for i in range(3):\n","                shap_df = pd.DataFrame(shap_values[i], columns=X_train.columns)\n","                shap_df_list[i].append(shap_df)\n","        elif len(shap_values) == 2:\n","            for i in range(2):\n","                shap_df = pd.DataFrame(shap_values[i], columns=X_train.columns)\n","                shap_df_list[i].append(shap_df)\n","        else:\n","            shap_df = pd.DataFrame(shap_values, columns=X_train.columns)\n","            shap_df_list[0].append(shap_df)\n","\n","    print()\n","    print('mean accuracy : ', mean_accuracy)\n","    print('mean precision : ', mean_precision)\n","    print('mean recall : ', mean_recall)\n","    print('mean f1 : ', mean_f1)\n","    print('mean roc_auc : ', mean_roc_auc)\n","    print()\n","\n","    metric_df.loc[len(metric_df)] = ['mean', mean_accuracy, mean_precision, mean_recall, mean_f1, mean_roc_auc]\n","    hyper_df_merged = pd.concat(hyper_df_list, ignore_index=True)\n","    feature_df_merged = pd.concat(feature_df_list, ignore_index=True)\n","\n","    result_df = pd.concat([metric_df, hyper_df_merged, feature_df_merged], axis=1)\n","\n","    return (shap_df_list, result_df)"]},{"cell_type":"markdown","metadata":{"id":"XWYC-SsdPNvC"},"source":["## Accuracy가 아닌 다른 metric을 기준으로 Optuna을 하려면 precision ~ roc_auc 주석 중 하나를 풀고 return 해주면 됩니다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ho9pcxlFPNvC"},"outputs":[],"source":["def InnerCrossValidation(clf, X, y, cv_method, n_fold=39):\n","    class_nums = len(set(y))\n","    if cv_method == 'loso':\n","        kfold = KFold(n_splits=39)\n","        splits = kfold.split(X)\n","    elif cv_method == 'k_fold':\n","        stratified_kfold = StratifiedKFold(n_splits=n_fold)\n","        splits = stratified_kfold.split(X, y)\n","    else:\n","        raise ValueError(\"cv_method must be 'loso' or 'k_fold'!\")\n","    \n","    train_X_len = len(X)\n","    if train_X_len % n_fold != 0:\n","        raise ValueError(f\"{train_X_len} / {n_fold} is not Integer!\")\n","\n","    y_true_list, y_pred_list = [], []\n","    y_pred_prob_list = []\n","    \n","    for train_idx, val_idx in splits:\n","        X_train, X_val = X.iloc[train_idx, :], X.iloc[val_idx, :]\n","        y_train, y_val = y[train_idx], y[val_idx]\n","        \n","        classifier = clone(clf)\n","\n","        # 모델을 학습한다\n","        classifier.fit(X_train, y_train)\n","\n","        y_pred = classifier.predict(X_val)\n","        y_pred_prob = classifier.predict_proba(X_val)\n","        \n","        # 실제, 예측 라벨을 저장한다\n","        y_true_list.extend(y_val)\n","        y_pred_list.extend(y_pred)\n","        y_pred_prob_list.extend(y_pred_prob)\n","    \n","    # 여기를 바꾸면 됩니다\n","    accuracy = accuracy_score(y_true_list, y_pred_list)\n","    # precision = precision_score(y_true_list, y_pred_list, average='macro')\n","    # recall = recall_score(y_true_list, y_pred_list, average='macro')\n","    # f1 = f1_score(y_true_list, y_pred_list, average='macro')\n","    # if class_nums > 2:\n","    #     roc_auc = roc_auc_score(y_val, y_pred_prob, average='macro', multi_class='ovr')\n","    # else:\n","    #     roc_auc = roc_auc_score(y_val, y_pred)\n","\n","    # 반환하는 변수를 바꿔줘야 합니다\n","    return accuracy"]},{"cell_type":"markdown","metadata":{"id":"nLjDUWzFPNvC"},"source":["# Lightgbm Bayesian"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7eX0HCZPNvC"},"outputs":[],"source":["class LGBMObjective(object):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","    \n","    def __call__(self, trial: Trial):\n","        lgbm_params = {\n","            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n","            'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-3, 1e-1),\n","            'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n","            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0, step=0.1),\n","            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n","            'subsample': trial.suggest_float('subsample', 0.6, 1.0, step=0.1), \n","            'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 5.0), # lambda_l1\n","            'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 5.0), # lambda_l2\n","            'random_state': 42\n","        }\n","\n","        clf = LGBMClassifier(**lgbm_params)\n","\n","        mean_accuracy = InnerCrossValidation(clf, self.X, self.y, cv_method, n_fold)\n","\n","        return mean_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npxDlCCYPNvD","outputId":"ef5c9336-5bd1-4386-a9b5-4a4bf414141e"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_nums :  2\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:56:24,242]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:56:28,944]\u001b[0m Trial 0 finished with value: 0.7663817663817664 and parameters: {'n_estimators': 326, 'learning_rate': 0.041828196885327226, 'num_leaves': 11, 'colsample_bytree': 1.0, 'min_child_samples': 11, 'subsample': 0.6, 'reg_alpha': 4.598137104176723, 'reg_lambda': 3.015806548435523}. Best is trial 0 with value: 0.7663817663817664.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7663817663817664\n","Best parameters :  {'n_estimators': 326, 'learning_rate': 0.041828196885327226, 'num_leaves': 11, 'colsample_bytree': 1.0, 'min_child_samples': 11, 'subsample': 0.6, 'reg_alpha': 4.598137104176723, 'reg_lambda': 3.015806548435523}\n","Selected features Num:  22\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_KSPS', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_CPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:56:32,159]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:56:34,457]\u001b[0m Trial 0 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 349, 'learning_rate': 0.0612219574420988, 'num_leaves': 4, 'colsample_bytree': 0.9, 'min_child_samples': 98, 'subsample': 0.9, 'reg_alpha': 4.485657317144603, 'reg_lambda': 4.243347733069335}. Best is trial 0 with value: 0.7692307692307693.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7692307692307693\n","Best parameters :  {'n_estimators': 349, 'learning_rate': 0.0612219574420988, 'num_leaves': 4, 'colsample_bytree': 0.9, 'min_child_samples': 98, 'subsample': 0.9, 'reg_alpha': 4.485657317144603, 'reg_lambda': 4.243347733069335}\n","Selected features Num:  26\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:56:37,931]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:56:39,105]\u001b[0m Trial 0 finished with value: 0.7834757834757835 and parameters: {'n_estimators': 109, 'learning_rate': 0.019111027638506712, 'num_leaves': 17, 'colsample_bytree': 0.8, 'min_child_samples': 38, 'subsample': 0.7, 'reg_alpha': 2.0403580070578125, 'reg_lambda': 4.168668623588548}. Best is trial 0 with value: 0.7834757834757835.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7834757834757835\n","Best parameters :  {'n_estimators': 109, 'learning_rate': 0.019111027638506712, 'num_leaves': 17, 'colsample_bytree': 0.8, 'min_child_samples': 38, 'subsample': 0.7, 'reg_alpha': 2.0403580070578125, 'reg_lambda': 4.168668623588548}\n","Selected features Num:  20\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_KSPS', 'sms_UB', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:56:42,539]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:56:43,645]\u001b[0m Trial 0 finished with value: 0.7378917378917379 and parameters: {'n_estimators': 191, 'learning_rate': 0.00843094252021283, 'num_leaves': 74, 'colsample_bytree': 0.7, 'min_child_samples': 100, 'subsample': 1.0, 'reg_alpha': 2.309609741938846, 'reg_lambda': 1.1511429889205282}. Best is trial 0 with value: 0.7378917378917379.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7378917378917379\n","Best parameters :  {'n_estimators': 191, 'learning_rate': 0.00843094252021283, 'num_leaves': 74, 'colsample_bytree': 0.7, 'min_child_samples': 100, 'subsample': 1.0, 'reg_alpha': 2.309609741938846, 'reg_lambda': 1.1511429889205282}\n","Selected features Num:  20\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_KSPS', 'sms_TER', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:56:46,656]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:56:57,341]\u001b[0m Trial 0 finished with value: 0.698005698005698 and parameters: {'n_estimators': 407, 'learning_rate': 0.0012484572570424528, 'num_leaves': 88, 'colsample_bytree': 0.8, 'min_child_samples': 10, 'subsample': 0.7, 'reg_alpha': 1.0493210989814603, 'reg_lambda': 3.5864232406048355}. Best is trial 0 with value: 0.698005698005698.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.698005698005698\n","Best parameters :  {'n_estimators': 407, 'learning_rate': 0.0012484572570424528, 'num_leaves': 88, 'colsample_bytree': 0.8, 'min_child_samples': 10, 'subsample': 0.7, 'reg_alpha': 1.0493210989814603, 'reg_lambda': 3.5864232406048355}\n","Selected features Num:  26\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:57:01,057]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:57:05,249]\u001b[0m Trial 0 finished with value: 0.7407407407407407 and parameters: {'n_estimators': 349, 'learning_rate': 0.003121674197906354, 'num_leaves': 98, 'colsample_bytree': 1.0, 'min_child_samples': 34, 'subsample': 0.9, 'reg_alpha': 2.6959365126750843, 'reg_lambda': 1.9227124101750066}. Best is trial 0 with value: 0.7407407407407407.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7407407407407407\n","Best parameters :  {'n_estimators': 349, 'learning_rate': 0.003121674197906354, 'num_leaves': 98, 'colsample_bytree': 1.0, 'min_child_samples': 34, 'subsample': 0.9, 'reg_alpha': 2.6959365126750843, 'reg_lambda': 1.9227124101750066}\n","Selected features Num:  22\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_KSPS', 'sms_UB', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:57:08,538]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:57:10,692]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 156, 'learning_rate': 0.002330162152553106, 'num_leaves': 35, 'colsample_bytree': 0.9, 'min_child_samples': 36, 'subsample': 0.6, 'reg_alpha': 4.082803578395933, 'reg_lambda': 4.253386502840787}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 156, 'learning_rate': 0.002330162152553106, 'num_leaves': 35, 'colsample_bytree': 0.9, 'min_child_samples': 36, 'subsample': 0.6, 'reg_alpha': 4.082803578395933, 'reg_lambda': 4.253386502840787}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:57:13,896]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:57:14,949]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 128, 'learning_rate': 0.0019690084556256058, 'num_leaves': 173, 'colsample_bytree': 0.9, 'min_child_samples': 85, 'subsample': 1.0, 'reg_alpha': 1.8094026384850443, 'reg_lambda': 4.472451797622179}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 128, 'learning_rate': 0.0019690084556256058, 'num_leaves': 173, 'colsample_bytree': 0.9, 'min_child_samples': 85, 'subsample': 1.0, 'reg_alpha': 1.8094026384850443, 'reg_lambda': 4.472451797622179}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:57:17,995]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:57:20,709]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 286, 'learning_rate': 0.002174771089508444, 'num_leaves': 25, 'colsample_bytree': 0.7, 'min_child_samples': 63, 'subsample': 1.0, 'reg_alpha': 2.4867520899279976, 'reg_lambda': 4.344221482329145}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 286, 'learning_rate': 0.002174771089508444, 'num_leaves': 25, 'colsample_bytree': 0.7, 'min_child_samples': 63, 'subsample': 1.0, 'reg_alpha': 2.4867520899279976, 'reg_lambda': 4.344221482329145}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:57:23,973]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:57:26,930]\u001b[0m Trial 0 finished with value: 0.7578347578347578 and parameters: {'n_estimators': 394, 'learning_rate': 0.015569897522855718, 'num_leaves': 256, 'colsample_bytree': 1.0, 'min_child_samples': 92, 'subsample': 0.8, 'reg_alpha': 4.868641130552245, 'reg_lambda': 2.2009521280899405}. Best is trial 0 with value: 0.7578347578347578.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7578347578347578\n","Best parameters :  {'n_estimators': 394, 'learning_rate': 0.015569897522855718, 'num_leaves': 256, 'colsample_bytree': 1.0, 'min_child_samples': 92, 'subsample': 0.8, 'reg_alpha': 4.868641130552245, 'reg_lambda': 2.2009521280899405}\n","Selected features Num:  20\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_KSPS', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_CPS', 'ws_COER']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:57:30,062]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:57:35,267]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 374, 'learning_rate': 0.03792628766378131, 'num_leaves': 137, 'colsample_bytree': 0.8, 'min_child_samples': 33, 'subsample': 1.0, 'reg_alpha': 3.5472148340725846, 'reg_lambda': 3.9054400768599282}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 374, 'learning_rate': 0.03792628766378131, 'num_leaves': 137, 'colsample_bytree': 0.8, 'min_child_samples': 33, 'subsample': 1.0, 'reg_alpha': 3.5472148340725846, 'reg_lambda': 3.9054400768599282}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:57:38,723]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:57:41,714]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 347, 'learning_rate': 0.0011170091211200413, 'num_leaves': 20, 'colsample_bytree': 0.7, 'min_child_samples': 53, 'subsample': 1.0, 'reg_alpha': 2.1056356843171504, 'reg_lambda': 3.1011893285028926}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 347, 'learning_rate': 0.0011170091211200413, 'num_leaves': 20, 'colsample_bytree': 0.7, 'min_child_samples': 53, 'subsample': 1.0, 'reg_alpha': 2.1056356843171504, 'reg_lambda': 3.1011893285028926}\n","Selected features Num:  26\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:57:45,113]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:57:51,190]\u001b[0m Trial 0 finished with value: 0.8062678062678063 and parameters: {'n_estimators': 293, 'learning_rate': 0.012959254012682305, 'num_leaves': 107, 'colsample_bytree': 1.0, 'min_child_samples': 18, 'subsample': 1.0, 'reg_alpha': 2.0693607525323405, 'reg_lambda': 2.4624786264547294}. Best is trial 0 with value: 0.8062678062678063.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8062678062678063\n","Best parameters :  {'n_estimators': 293, 'learning_rate': 0.012959254012682305, 'num_leaves': 107, 'colsample_bytree': 1.0, 'min_child_samples': 18, 'subsample': 1.0, 'reg_alpha': 2.0693607525323405, 'reg_lambda': 2.4624786264547294}\n","Selected features Num:  26\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_TER', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:57:54,417]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:57:59,537]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 358, 'learning_rate': 0.0011437202114755963, 'num_leaves': 174, 'colsample_bytree': 0.6, 'min_child_samples': 29, 'subsample': 0.7, 'reg_alpha': 1.4127631530107112, 'reg_lambda': 4.595678856177995}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 358, 'learning_rate': 0.0011437202114755963, 'num_leaves': 174, 'colsample_bytree': 0.6, 'min_child_samples': 29, 'subsample': 0.7, 'reg_alpha': 1.4127631530107112, 'reg_lambda': 4.595678856177995}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:58:02,520]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:58:05,624]\u001b[0m Trial 0 finished with value: 0.7720797720797721 and parameters: {'n_estimators': 192, 'learning_rate': 0.012162368305547388, 'num_leaves': 85, 'colsample_bytree': 0.8, 'min_child_samples': 25, 'subsample': 0.7, 'reg_alpha': 4.5053033594117124, 'reg_lambda': 1.2404170981330447}. Best is trial 0 with value: 0.7720797720797721.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7720797720797721\n","Best parameters :  {'n_estimators': 192, 'learning_rate': 0.012162368305547388, 'num_leaves': 85, 'colsample_bytree': 0.8, 'min_child_samples': 25, 'subsample': 0.7, 'reg_alpha': 4.5053033594117124, 'reg_lambda': 1.2404170981330447}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_COER']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:58:08,849]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:58:21,636]\u001b[0m Trial 0 finished with value: 0.7834757834757835 and parameters: {'n_estimators': 264, 'learning_rate': 0.004899143727929381, 'num_leaves': 248, 'colsample_bytree': 0.7, 'min_child_samples': 5, 'subsample': 0.7, 'reg_alpha': 1.4775547601378491, 'reg_lambda': 2.7678965136158777}. Best is trial 0 with value: 0.7834757834757835.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7834757834757835\n","Best parameters :  {'n_estimators': 264, 'learning_rate': 0.004899143727929381, 'num_leaves': 248, 'colsample_bytree': 0.7, 'min_child_samples': 5, 'subsample': 0.7, 'reg_alpha': 1.4775547601378491, 'reg_lambda': 2.7678965136158777}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:58:25,437]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:58:36,848]\u001b[0m Trial 0 finished with value: 0.7236467236467237 and parameters: {'n_estimators': 418, 'learning_rate': 0.0013326971862141202, 'num_leaves': 119, 'colsample_bytree': 0.7, 'min_child_samples': 9, 'subsample': 0.9, 'reg_alpha': 1.1064643484441006, 'reg_lambda': 4.6180148955551115}. Best is trial 0 with value: 0.7236467236467237.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7236467236467237\n","Best parameters :  {'n_estimators': 418, 'learning_rate': 0.0013326971862141202, 'num_leaves': 119, 'colsample_bytree': 0.7, 'min_child_samples': 9, 'subsample': 0.9, 'reg_alpha': 1.1064643484441006, 'reg_lambda': 4.6180148955551115}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:58:40,283]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:58:43,387]\u001b[0m Trial 0 finished with value: 0.8005698005698005 and parameters: {'n_estimators': 172, 'learning_rate': 0.03201853211211412, 'num_leaves': 75, 'colsample_bytree': 0.7, 'min_child_samples': 26, 'subsample': 0.6, 'reg_alpha': 1.7977515723933508, 'reg_lambda': 3.7823778297767583}. Best is trial 0 with value: 0.8005698005698005.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8005698005698005\n","Best parameters :  {'n_estimators': 172, 'learning_rate': 0.03201853211211412, 'num_leaves': 75, 'colsample_bytree': 0.7, 'min_child_samples': 26, 'subsample': 0.6, 'reg_alpha': 1.7977515723933508, 'reg_lambda': 3.7823778297767583}\n","Selected features Num:  42\n","Selected features :  ['transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:58:47,109]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:58:55,188]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 479, 'learning_rate': 0.003068819059818019, 'num_leaves': 69, 'colsample_bytree': 1.0, 'min_child_samples': 23, 'subsample': 0.9, 'reg_alpha': 4.685834341154296, 'reg_lambda': 1.4007286843218147}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 479, 'learning_rate': 0.003068819059818019, 'num_leaves': 69, 'colsample_bytree': 1.0, 'min_child_samples': 23, 'subsample': 0.9, 'reg_alpha': 4.685834341154296, 'reg_lambda': 1.4007286843218147}\n","Selected features Num:  22\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_KSPS', 'sms_TER', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:58:58,558]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:02,801]\u001b[0m Trial 0 finished with value: 0.7264957264957265 and parameters: {'n_estimators': 437, 'learning_rate': 0.0019123947775547044, 'num_leaves': 248, 'colsample_bytree': 0.7, 'min_child_samples': 51, 'subsample': 0.6, 'reg_alpha': 1.5725838601297135, 'reg_lambda': 2.341440475313992}. Best is trial 0 with value: 0.7264957264957265.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7264957264957265\n","Best parameters :  {'n_estimators': 437, 'learning_rate': 0.0019123947775547044, 'num_leaves': 248, 'colsample_bytree': 0.7, 'min_child_samples': 51, 'subsample': 0.6, 'reg_alpha': 1.5725838601297135, 'reg_lambda': 2.341440475313992}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:59:05,972]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:08,428]\u001b[0m Trial 0 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 340, 'learning_rate': 0.03122791933012022, 'num_leaves': 8, 'colsample_bytree': 0.6, 'min_child_samples': 86, 'subsample': 0.9, 'reg_alpha': 3.7630382919857683, 'reg_lambda': 2.0374680821735582}. Best is trial 0 with value: 0.7777777777777778.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7777777777777778\n","Best parameters :  {'n_estimators': 340, 'learning_rate': 0.03122791933012022, 'num_leaves': 8, 'colsample_bytree': 0.6, 'min_child_samples': 86, 'subsample': 0.9, 'reg_alpha': 3.7630382919857683, 'reg_lambda': 2.0374680821735582}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:59:11,269]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:12,397]\u001b[0m Trial 0 finished with value: 0.7521367521367521 and parameters: {'n_estimators': 125, 'learning_rate': 0.0070449926168001595, 'num_leaves': 154, 'colsample_bytree': 1.0, 'min_child_samples': 65, 'subsample': 0.7, 'reg_alpha': 3.985944363264353, 'reg_lambda': 1.1940929553784967}. Best is trial 0 with value: 0.7521367521367521.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7521367521367521\n","Best parameters :  {'n_estimators': 125, 'learning_rate': 0.0070449926168001595, 'num_leaves': 154, 'colsample_bytree': 1.0, 'min_child_samples': 65, 'subsample': 0.7, 'reg_alpha': 3.985944363264353, 'reg_lambda': 1.1940929553784967}\n","Selected features Num:  30\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:59:15,274]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:20,169]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 416, 'learning_rate': 0.0012022342280873046, 'num_leaves': 141, 'colsample_bytree': 0.9, 'min_child_samples': 36, 'subsample': 0.9, 'reg_alpha': 4.7989233674103975, 'reg_lambda': 4.275255130064592}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 416, 'learning_rate': 0.0012022342280873046, 'num_leaves': 141, 'colsample_bytree': 0.9, 'min_child_samples': 36, 'subsample': 0.9, 'reg_alpha': 4.7989233674103975, 'reg_lambda': 4.275255130064592}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:59:22,893]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:25,913]\u001b[0m Trial 0 finished with value: 0.7207977207977208 and parameters: {'n_estimators': 364, 'learning_rate': 0.0019979825025623972, 'num_leaves': 99, 'colsample_bytree': 0.9, 'min_child_samples': 63, 'subsample': 0.9, 'reg_alpha': 4.229565907711436, 'reg_lambda': 3.60580819209842}. Best is trial 0 with value: 0.7207977207977208.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7207977207977208\n","Best parameters :  {'n_estimators': 364, 'learning_rate': 0.0019979825025623972, 'num_leaves': 99, 'colsample_bytree': 0.9, 'min_child_samples': 63, 'subsample': 0.9, 'reg_alpha': 4.229565907711436, 'reg_lambda': 3.60580819209842}\n","Selected features Num:  40\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:59:28,438]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:31,424]\u001b[0m Trial 0 finished with value: 0.7663817663817664 and parameters: {'n_estimators': 451, 'learning_rate': 0.010978963230014944, 'num_leaves': 63, 'colsample_bytree': 1.0, 'min_child_samples': 70, 'subsample': 0.8, 'reg_alpha': 4.103951793288785, 'reg_lambda': 3.634549658186457}. Best is trial 0 with value: 0.7663817663817664.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7663817663817664\n","Best parameters :  {'n_estimators': 451, 'learning_rate': 0.010978963230014944, 'num_leaves': 63, 'colsample_bytree': 1.0, 'min_child_samples': 70, 'subsample': 0.8, 'reg_alpha': 4.103951793288785, 'reg_lambda': 3.634549658186457}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:59:33,974]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:37,471]\u001b[0m Trial 0 finished with value: 0.7378917378917379 and parameters: {'n_estimators': 334, 'learning_rate': 0.0024822052503172477, 'num_leaves': 98, 'colsample_bytree': 0.6, 'min_child_samples': 37, 'subsample': 1.0, 'reg_alpha': 2.5780652030136078, 'reg_lambda': 2.566386846577355}. Best is trial 0 with value: 0.7378917378917379.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7378917378917379\n","Best parameters :  {'n_estimators': 334, 'learning_rate': 0.0024822052503172477, 'num_leaves': 98, 'colsample_bytree': 0.6, 'min_child_samples': 37, 'subsample': 1.0, 'reg_alpha': 2.5780652030136078, 'reg_lambda': 2.566386846577355}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:59:39,939]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:46,802]\u001b[0m Trial 0 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 282, 'learning_rate': 0.021968098184085922, 'num_leaves': 108, 'colsample_bytree': 0.9, 'min_child_samples': 5, 'subsample': 0.8, 'reg_alpha': 4.885572452898446, 'reg_lambda': 1.452398847365918}. Best is trial 0 with value: 0.7777777777777778.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7777777777777778\n","Best parameters :  {'n_estimators': 282, 'learning_rate': 0.021968098184085922, 'num_leaves': 108, 'colsample_bytree': 0.9, 'min_child_samples': 5, 'subsample': 0.8, 'reg_alpha': 4.885572452898446, 'reg_lambda': 1.452398847365918}\n","Selected features Num:  42\n","Selected features :  ['transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:59:49,900]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:54,756]\u001b[0m Trial 0 finished with value: 0.7008547008547008 and parameters: {'n_estimators': 353, 'learning_rate': 0.0013001512363923263, 'num_leaves': 40, 'colsample_bytree': 1.0, 'min_child_samples': 18, 'subsample': 0.8, 'reg_alpha': 3.352450527676775, 'reg_lambda': 1.4991214013895884}. Best is trial 0 with value: 0.7008547008547008.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7008547008547008\n","Best parameters :  {'n_estimators': 353, 'learning_rate': 0.0013001512363923263, 'num_leaves': 40, 'colsample_bytree': 1.0, 'min_child_samples': 18, 'subsample': 0.8, 'reg_alpha': 3.352450527676775, 'reg_lambda': 1.4991214013895884}\n","Selected features Num:  40\n","Selected features :  ['transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:59:57,067]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:59:59,772]\u001b[0m Trial 0 finished with value: 0.7578347578347578 and parameters: {'n_estimators': 464, 'learning_rate': 0.0069770895613776055, 'num_leaves': 111, 'colsample_bytree': 0.8, 'min_child_samples': 99, 'subsample': 1.0, 'reg_alpha': 4.221694949280927, 'reg_lambda': 2.560042184275416}. Best is trial 0 with value: 0.7578347578347578.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7578347578347578\n","Best parameters :  {'n_estimators': 464, 'learning_rate': 0.0069770895613776055, 'num_leaves': 111, 'colsample_bytree': 0.8, 'min_child_samples': 99, 'subsample': 1.0, 'reg_alpha': 4.221694949280927, 'reg_lambda': 2.560042184275416}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:01,882]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:08,310]\u001b[0m Trial 0 finished with value: 0.7948717948717948 and parameters: {'n_estimators': 237, 'learning_rate': 0.03694474446284191, 'num_leaves': 235, 'colsample_bytree': 0.6, 'min_child_samples': 6, 'subsample': 1.0, 'reg_alpha': 1.633287437594765, 'reg_lambda': 2.2775525850159215}. Best is trial 0 with value: 0.7948717948717948.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7948717948717948\n","Best parameters :  {'n_estimators': 237, 'learning_rate': 0.03694474446284191, 'num_leaves': 235, 'colsample_bytree': 0.6, 'min_child_samples': 6, 'subsample': 1.0, 'reg_alpha': 1.633287437594765, 'reg_lambda': 2.2775525850159215}\n","Selected features Num:  42\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:10,405]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:18,895]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 447, 'learning_rate': 0.004052389435096838, 'num_leaves': 140, 'colsample_bytree': 0.9, 'min_child_samples': 7, 'subsample': 0.7, 'reg_alpha': 2.872569866083548, 'reg_lambda': 1.0237856183758054}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 447, 'learning_rate': 0.004052389435096838, 'num_leaves': 140, 'colsample_bytree': 0.9, 'min_child_samples': 7, 'subsample': 0.7, 'reg_alpha': 2.872569866083548, 'reg_lambda': 1.0237856183758054}\n","Selected features Num:  42\n","Selected features :  ['transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:20,983]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:22,253]\u001b[0m Trial 0 finished with value: 0.7635327635327636 and parameters: {'n_estimators': 247, 'learning_rate': 0.005791292164500986, 'num_leaves': 89, 'colsample_bytree': 0.7, 'min_child_samples': 94, 'subsample': 0.9, 'reg_alpha': 1.9815565134703714, 'reg_lambda': 3.7630652323466034}. Best is trial 0 with value: 0.7635327635327636.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7635327635327636\n","Best parameters :  {'n_estimators': 247, 'learning_rate': 0.005791292164500986, 'num_leaves': 89, 'colsample_bytree': 0.7, 'min_child_samples': 94, 'subsample': 0.9, 'reg_alpha': 1.9815565134703714, 'reg_lambda': 3.7630652323466034}\n","Selected features Num:  40\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:23,940]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:25,795]\u001b[0m Trial 0 finished with value: 0.7578347578347578 and parameters: {'n_estimators': 365, 'learning_rate': 0.032023088597318665, 'num_leaves': 246, 'colsample_bytree': 0.9, 'min_child_samples': 99, 'subsample': 0.8, 'reg_alpha': 4.549045924245558, 'reg_lambda': 3.0076570075515074}. Best is trial 0 with value: 0.7578347578347578.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7578347578347578\n","Best parameters :  {'n_estimators': 365, 'learning_rate': 0.032023088597318665, 'num_leaves': 246, 'colsample_bytree': 0.9, 'min_child_samples': 99, 'subsample': 0.8, 'reg_alpha': 4.549045924245558, 'reg_lambda': 3.0076570075515074}\n","Selected features Num:  40\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:27,468]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:29,527]\u001b[0m Trial 0 finished with value: 0.7806267806267806 and parameters: {'n_estimators': 379, 'learning_rate': 0.04311583605153956, 'num_leaves': 19, 'colsample_bytree': 0.6, 'min_child_samples': 81, 'subsample': 0.7, 'reg_alpha': 3.1209994454886107, 'reg_lambda': 2.2769858617279555}. Best is trial 0 with value: 0.7806267806267806.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7806267806267806\n","Best parameters :  {'n_estimators': 379, 'learning_rate': 0.04311583605153956, 'num_leaves': 19, 'colsample_bytree': 0.6, 'min_child_samples': 81, 'subsample': 0.7, 'reg_alpha': 3.1209994454886107, 'reg_lambda': 2.2769858617279555}\n","Selected features Num:  44\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:31,560]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:32,778]\u001b[0m Trial 0 finished with value: 0.7435897435897436 and parameters: {'n_estimators': 227, 'learning_rate': 0.004295047086868529, 'num_leaves': 66, 'colsample_bytree': 0.7, 'min_child_samples': 64, 'subsample': 1.0, 'reg_alpha': 2.6143678175597462, 'reg_lambda': 2.0163393802003515}. Best is trial 0 with value: 0.7435897435897436.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7435897435897436\n","Best parameters :  {'n_estimators': 227, 'learning_rate': 0.004295047086868529, 'num_leaves': 66, 'colsample_bytree': 0.7, 'min_child_samples': 64, 'subsample': 1.0, 'reg_alpha': 2.6143678175597462, 'reg_lambda': 2.0163393802003515}\n","Selected features Num:  20\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_KSPS', 'sms_TER', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:34,565]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:38,626]\u001b[0m Trial 0 finished with value: 0.8062678062678063 and parameters: {'n_estimators': 420, 'learning_rate': 0.0090054808679711, 'num_leaves': 218, 'colsample_bytree': 0.8, 'min_child_samples': 27, 'subsample': 0.7, 'reg_alpha': 2.621869646321484, 'reg_lambda': 2.6560506745915067}. Best is trial 0 with value: 0.8062678062678063.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8062678062678063\n","Best parameters :  {'n_estimators': 420, 'learning_rate': 0.0090054808679711, 'num_leaves': 218, 'colsample_bytree': 0.8, 'min_child_samples': 27, 'subsample': 0.7, 'reg_alpha': 2.621869646321484, 'reg_lambda': 2.6560506745915067}\n","Selected features Num:  40\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:40,412]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:42,715]\u001b[0m Trial 0 finished with value: 0.7948717948717948 and parameters: {'n_estimators': 337, 'learning_rate': 0.0388629517524077, 'num_leaves': 249, 'colsample_bytree': 0.6, 'min_child_samples': 46, 'subsample': 0.7, 'reg_alpha': 4.435001221361858, 'reg_lambda': 2.617603849379234}. Best is trial 0 with value: 0.7948717948717948.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7948717948717948\n","Best parameters :  {'n_estimators': 337, 'learning_rate': 0.0388629517524077, 'num_leaves': 249, 'colsample_bytree': 0.6, 'min_child_samples': 46, 'subsample': 0.7, 'reg_alpha': 4.435001221361858, 'reg_lambda': 2.617603849379234}\n","Selected features Num:  42\n","Selected features :  ['transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.3333333333333333\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:44,378]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:45,411]\u001b[0m Trial 0 finished with value: 0.7521367521367521 and parameters: {'n_estimators': 194, 'learning_rate': 0.008831578251122248, 'num_leaves': 119, 'colsample_bytree': 0.6, 'min_child_samples': 76, 'subsample': 0.8, 'reg_alpha': 3.446032884683929, 'reg_lambda': 3.8385900999435916}. Best is trial 0 with value: 0.7521367521367521.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7521367521367521\n","Best parameters :  {'n_estimators': 194, 'learning_rate': 0.008831578251122248, 'num_leaves': 119, 'colsample_bytree': 0.6, 'min_child_samples': 76, 'subsample': 0.8, 'reg_alpha': 3.446032884683929, 'reg_lambda': 3.8385900999435916}\n","Selected features Num:  42\n","Selected features :  ['transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.4444444444444444\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:47,188]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:47,930]\u001b[0m Trial 0 finished with value: 0.7464387464387464 and parameters: {'n_estimators': 123, 'learning_rate': 0.007086857514124043, 'num_leaves': 69, 'colsample_bytree': 0.7, 'min_child_samples': 64, 'subsample': 0.8, 'reg_alpha': 3.9606640415638066, 'reg_lambda': 3.7021154006513943}. Best is trial 0 with value: 0.7464387464387464.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7464387464387464\n","Best parameters :  {'n_estimators': 123, 'learning_rate': 0.007086857514124043, 'num_leaves': 69, 'colsample_bytree': 0.7, 'min_child_samples': 64, 'subsample': 0.8, 'reg_alpha': 3.9606640415638066, 'reg_lambda': 3.7021154006513943}\n","Selected features Num:  42\n","Selected features :  ['Transition_Camera', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 01:00:49,609]\u001b[0m A new study created in memory with name: lightgbm Study\u001b[0m\n","\u001b[32m[I 2022-08-31 01:00:52,639]\u001b[0m Trial 0 finished with value: 0.7806267806267806 and parameters: {'n_estimators': 462, 'learning_rate': 0.006713100691044636, 'num_leaves': 142, 'colsample_bytree': 0.6, 'min_child_samples': 43, 'subsample': 1.0, 'reg_alpha': 3.909680680593169, 'reg_lambda': 4.40560655815576}. Best is trial 0 with value: 0.7806267806267806.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7806267806267806\n","Best parameters :  {'n_estimators': 462, 'learning_rate': 0.006713100691044636, 'num_leaves': 142, 'colsample_bytree': 0.6, 'min_child_samples': 43, 'subsample': 1.0, 'reg_alpha': 3.909680680593169, 'reg_lambda': 4.40560655815576}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.7777777777777778\n","\n","mean accuracy :  0.7361111111111113\n","mean precision :  0.7361111111111113\n","mean recall :  0.6437500000000002\n","mean f1 :  0.6063560744810746\n","mean roc_auc :  0.6437500000000002\n","\n"]}],"source":["clf = LGBMClassifier(random_state=42)\n","shap_df_list, metric_df = NestedCVwithOptuna(LGBMObjective, clf, 'lightgbm')"]},{"cell_type":"markdown","metadata":{"id":"KAwkD_iTPNvD"},"source":["## 40개의 모델의 개별 performance metric + 평균 performnace metric을 저장한다\n","## 각 모델별 test set의 feature에 따른 shap value를 저장한다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iAelAOEDPNvE"},"outputs":[],"source":["if label_name == 'three_label':\n","    shap_values_df_0 = pd.concat(shap_df_list[0])\n","    shap_values_df_1 = pd.concat(shap_df_list[1])\n","    shap_values_df_2 = pd.concat(shap_df_list[2])\n","\n","    with pd.ExcelWriter(f\"./lgbm_result.xlsx\") as writer:\n","        metric_df.to_excel(writer, sheet_name=\"performance metric\", index=False)\n","        shap_values_df_0.to_excel(writer, sheet_name=\"shap_list_0\", index=False)\n","        shap_values_df_1.to_excel(writer, sheet_name=\"shap_list_1\", index=False)\n","        shap_values_df_2.to_excel(writer, sheet_name=\"shap_list_2\", index=False)\n","\n","if label_name != 'three_label':\n","    shap_values_df = pd.concat(shap_df_list[0])\n","\n","    with pd.ExcelWriter(f\"./lgbm_result.xlsx\") as writer:\n","        metric_df.to_excel(writer, sheet_name=\"performance metric\", index=False)\n","        shap_values_df.to_excel(writer, sheet_name=\"shap_list\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"Y7O0WGjCPNvE"},"source":["# Xgboost Bayesian"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IS5rRwDoPNvE"},"outputs":[],"source":["class XBGObjective(object):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __call__(self, trial: Trial):    \n","        xgb_params = {\n","            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n","            'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-1),\n","            'max_depth': trial.suggest_int('max_depth', 3, 10),\n","            'min_child_weight': trial.suggest_int('min_child_weight', 1, 9),\n","            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.1),\n","            'subsample': trial.suggest_float('subsample', 0.5, 1.0, step=0.1),\n","            'gamma': trial.suggest_float('gamma', 0.0, 5.0, step=0.1),\n","            'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 5.0), # lambda_l1\n","            'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 5.0), # lambda_l2\n","            'random_state': 42\n","        }\n","\n","        clf = XGBClassifier(**xgb_params)\n","\n","        mean_accuracy = InnerCrossValidation(clf, self.X, self.y, cv_method, n_fold)\n","\n","        return mean_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZb9_pcMPNvE","outputId":"a7d3743a-c179-49c0-e2bb-af95a10b06e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_nums :  2\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:40:22,751]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:40:30,160]\u001b[0m Trial 0 finished with value: 0.7834757834757835 and parameters: {'n_estimators': 479, 'learning_rate': 0.02027461225419885, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 1.0, 'subsample': 0.5, 'gamma': 1.7000000000000002, 'reg_alpha': 3.2839562817091927, 'reg_lambda': 4.132672346068551}. Best is trial 0 with value: 0.7834757834757835.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7834757834757835\n","Best parameters :  {'n_estimators': 479, 'learning_rate': 0.02027461225419885, 'max_depth': 5, 'min_child_weight': 4, 'colsample_bytree': 1.0, 'subsample': 0.5, 'gamma': 1.7000000000000002, 'reg_alpha': 3.2839562817091927, 'reg_lambda': 4.132672346068551}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:40:41,357]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:40:49,836]\u001b[0m Trial 0 finished with value: 0.7578347578347578 and parameters: {'n_estimators': 409, 'learning_rate': 0.0003339333528905027, 'max_depth': 7, 'min_child_weight': 4, 'colsample_bytree': 0.9, 'subsample': 0.7, 'gamma': 3.2, 'reg_alpha': 2.5002626588819394, 'reg_lambda': 4.506800261541564}. Best is trial 0 with value: 0.7578347578347578.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7578347578347578\n","Best parameters :  {'n_estimators': 409, 'learning_rate': 0.0003339333528905027, 'max_depth': 7, 'min_child_weight': 4, 'colsample_bytree': 0.9, 'subsample': 0.7, 'gamma': 3.2, 'reg_alpha': 2.5002626588819394, 'reg_lambda': 4.506800261541564}\n","Selected features Num:  38\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:41:01,665]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:41:05,371]\u001b[0m Trial 0 finished with value: 0.8034188034188035 and parameters: {'n_estimators': 210, 'learning_rate': 0.032140835252486157, 'max_depth': 8, 'min_child_weight': 7, 'colsample_bytree': 0.7, 'subsample': 1.0, 'gamma': 4.1000000000000005, 'reg_alpha': 2.286787890754746, 'reg_lambda': 4.389866721039714}. Best is trial 0 with value: 0.8034188034188035.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8034188034188035\n","Best parameters :  {'n_estimators': 210, 'learning_rate': 0.032140835252486157, 'max_depth': 8, 'min_child_weight': 7, 'colsample_bytree': 0.7, 'subsample': 1.0, 'gamma': 4.1000000000000005, 'reg_alpha': 2.286787890754746, 'reg_lambda': 4.389866721039714}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:41:16,309]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:41:20,928]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 302, 'learning_rate': 0.021660054423348372, 'max_depth': 7, 'min_child_weight': 5, 'colsample_bytree': 0.8, 'subsample': 0.5, 'gamma': 0.30000000000000004, 'reg_alpha': 3.6050053205141652, 'reg_lambda': 3.1569848062478187}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 302, 'learning_rate': 0.021660054423348372, 'max_depth': 7, 'min_child_weight': 5, 'colsample_bytree': 0.8, 'subsample': 0.5, 'gamma': 0.30000000000000004, 'reg_alpha': 3.6050053205141652, 'reg_lambda': 3.1569848062478187}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:41:32,325]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:41:34,194]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 106, 'learning_rate': 0.011976645026504843, 'max_depth': 5, 'min_child_weight': 7, 'colsample_bytree': 0.6, 'subsample': 0.7, 'gamma': 2.2, 'reg_alpha': 1.744512679793977, 'reg_lambda': 2.187921654695226}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 106, 'learning_rate': 0.011976645026504843, 'max_depth': 5, 'min_child_weight': 7, 'colsample_bytree': 0.6, 'subsample': 0.7, 'gamma': 2.2, 'reg_alpha': 1.744512679793977, 'reg_lambda': 2.187921654695226}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:41:45,285]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:41:49,510]\u001b[0m Trial 0 finished with value: 0.7863247863247863 and parameters: {'n_estimators': 228, 'learning_rate': 0.08345219130090421, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.5, 'subsample': 0.6, 'gamma': 0.4, 'reg_alpha': 3.261231399479197, 'reg_lambda': 3.3657507911465476}. Best is trial 0 with value: 0.7863247863247863.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7863247863247863\n","Best parameters :  {'n_estimators': 228, 'learning_rate': 0.08345219130090421, 'max_depth': 4, 'min_child_weight': 1, 'colsample_bytree': 0.5, 'subsample': 0.6, 'gamma': 0.4, 'reg_alpha': 3.261231399479197, 'reg_lambda': 3.3657507911465476}\n","Selected features Num:  36\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:42:00,962]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:42:03,378]\u001b[0m Trial 0 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 105, 'learning_rate': 0.0001748046393186764, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 1.0, 'subsample': 0.9, 'gamma': 4.7, 'reg_alpha': 2.8908365909360403, 'reg_lambda': 1.0834529684620184}. Best is trial 0 with value: 0.7692307692307693.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7692307692307693\n","Best parameters :  {'n_estimators': 105, 'learning_rate': 0.0001748046393186764, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 1.0, 'subsample': 0.9, 'gamma': 4.7, 'reg_alpha': 2.8908365909360403, 'reg_lambda': 1.0834529684620184}\n","Selected features Num:  30\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_COER']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:42:14,549]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:42:20,520]\u001b[0m Trial 0 finished with value: 0.7663817663817664 and parameters: {'n_estimators': 431, 'learning_rate': 0.00010630767728356801, 'max_depth': 3, 'min_child_weight': 8, 'colsample_bytree': 0.5, 'subsample': 0.7, 'gamma': 1.8, 'reg_alpha': 2.251494842756942, 'reg_lambda': 2.541727134026845}. Best is trial 0 with value: 0.7663817663817664.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7663817663817664\n","Best parameters :  {'n_estimators': 431, 'learning_rate': 0.00010630767728356801, 'max_depth': 3, 'min_child_weight': 8, 'colsample_bytree': 0.5, 'subsample': 0.7, 'gamma': 1.8, 'reg_alpha': 2.251494842756942, 'reg_lambda': 2.541727134026845}\n","Selected features Num:  36\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:42:32,019]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:42:34,342]\u001b[0m Trial 0 finished with value: 0.7264957264957265 and parameters: {'n_estimators': 80, 'learning_rate': 0.00022507242779673428, 'max_depth': 5, 'min_child_weight': 2, 'colsample_bytree': 1.0, 'subsample': 0.9, 'gamma': 4.2, 'reg_alpha': 4.793460334043983, 'reg_lambda': 3.2751639663941035}. Best is trial 0 with value: 0.7264957264957265.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7264957264957265\n","Best parameters :  {'n_estimators': 80, 'learning_rate': 0.00022507242779673428, 'max_depth': 5, 'min_child_weight': 2, 'colsample_bytree': 1.0, 'subsample': 0.9, 'gamma': 4.2, 'reg_alpha': 4.793460334043983, 'reg_lambda': 3.2751639663941035}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:42:45,561]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:42:53,629]\u001b[0m Trial 0 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 436, 'learning_rate': 0.0334150158435057, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 1.0, 'subsample': 0.6, 'gamma': 3.6, 'reg_alpha': 4.277340788244047, 'reg_lambda': 4.769042967352705}. Best is trial 0 with value: 0.7777777777777778.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7777777777777778\n","Best parameters :  {'n_estimators': 436, 'learning_rate': 0.0334150158435057, 'max_depth': 8, 'min_child_weight': 4, 'colsample_bytree': 1.0, 'subsample': 0.6, 'gamma': 3.6, 'reg_alpha': 4.277340788244047, 'reg_lambda': 4.769042967352705}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:43:04,959]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:43:07,531]\u001b[0m Trial 0 finished with value: 0.8005698005698005 and parameters: {'n_estimators': 154, 'learning_rate': 0.0430205902564489, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.6, 'subsample': 0.5, 'gamma': 4.9, 'reg_alpha': 1.1528395728303549, 'reg_lambda': 4.5337296422439}. Best is trial 0 with value: 0.8005698005698005.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8005698005698005\n","Best parameters :  {'n_estimators': 154, 'learning_rate': 0.0430205902564489, 'max_depth': 4, 'min_child_weight': 3, 'colsample_bytree': 0.6, 'subsample': 0.5, 'gamma': 4.9, 'reg_alpha': 1.1528395728303549, 'reg_lambda': 4.5337296422439}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:43:18,768]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:43:27,475]\u001b[0m Trial 0 finished with value: 0.8062678062678063 and parameters: {'n_estimators': 442, 'learning_rate': 0.01847893810969411, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.6, 'subsample': 0.7, 'gamma': 0.8, 'reg_alpha': 3.4491800308886726, 'reg_lambda': 1.3133689568371976}. Best is trial 0 with value: 0.8062678062678063.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8062678062678063\n","Best parameters :  {'n_estimators': 442, 'learning_rate': 0.01847893810969411, 'max_depth': 4, 'min_child_weight': 2, 'colsample_bytree': 0.6, 'subsample': 0.7, 'gamma': 0.8, 'reg_alpha': 3.4491800308886726, 'reg_lambda': 1.3133689568371976}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:43:38,964]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:43:42,377]\u001b[0m Trial 0 finished with value: 0.7635327635327636 and parameters: {'n_estimators': 127, 'learning_rate': 0.0003436860472078395, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.8, 'subsample': 0.7, 'gamma': 4.3, 'reg_alpha': 1.3721986254583904, 'reg_lambda': 4.694454713267508}. Best is trial 0 with value: 0.7635327635327636.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7635327635327636\n","Best parameters :  {'n_estimators': 127, 'learning_rate': 0.0003436860472078395, 'max_depth': 7, 'min_child_weight': 1, 'colsample_bytree': 0.8, 'subsample': 0.7, 'gamma': 4.3, 'reg_alpha': 1.3721986254583904, 'reg_lambda': 4.694454713267508}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:43:53,558]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:43:58,361]\u001b[0m Trial 0 finished with value: 0.7977207977207977 and parameters: {'n_estimators': 377, 'learning_rate': 0.06835777761953526, 'max_depth': 4, 'min_child_weight': 8, 'colsample_bytree': 1.0, 'subsample': 0.5, 'gamma': 1.0, 'reg_alpha': 4.544877425935718, 'reg_lambda': 4.964385808762373}. Best is trial 0 with value: 0.7977207977207977.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7977207977207977\n","Best parameters :  {'n_estimators': 377, 'learning_rate': 0.06835777761953526, 'max_depth': 4, 'min_child_weight': 8, 'colsample_bytree': 1.0, 'subsample': 0.5, 'gamma': 1.0, 'reg_alpha': 4.544877425935718, 'reg_lambda': 4.964385808762373}\n","Selected features Num:  30\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:44:10,261]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:44:11,609]\u001b[0m Trial 0 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 106, 'learning_rate': 0.07655663354173123, 'max_depth': 6, 'min_child_weight': 9, 'colsample_bytree': 0.6, 'subsample': 0.5, 'gamma': 0.2, 'reg_alpha': 3.8339687195753274, 'reg_lambda': 3.1255667678312573}. Best is trial 0 with value: 0.7777777777777778.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7777777777777778\n","Best parameters :  {'n_estimators': 106, 'learning_rate': 0.07655663354173123, 'max_depth': 6, 'min_child_weight': 9, 'colsample_bytree': 0.6, 'subsample': 0.5, 'gamma': 0.2, 'reg_alpha': 3.8339687195753274, 'reg_lambda': 3.1255667678312573}\n","Selected features Num:  20\n","Selected features :  ['average_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-31 00:44:22,839]\u001b[0m A new study created in memory with name: xgboost Study\u001b[0m\n","\u001b[32m[I 2022-08-31 00:44:26,107]\u001b[0m Trial 0 finished with value: 0.8205128205128205 and parameters: {'n_estimators': 111, 'learning_rate': 0.02681787493968089, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 1.0, 'subsample': 1.0, 'gamma': 2.4000000000000004, 'reg_alpha': 3.7160525187400353, 'reg_lambda': 1.5027077252048167}. Best is trial 0 with value: 0.8205128205128205.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8205128205128205\n","Best parameters :  {'n_estimators': 111, 'learning_rate': 0.02681787493968089, 'max_depth': 9, 'min_child_weight': 4, 'colsample_bytree': 1.0, 'subsample': 1.0, 'gamma': 2.4000000000000004, 'reg_alpha': 3.7160525187400353, 'reg_lambda': 1.5027077252048167}\n","Selected features Num:  42\n","Selected features :  ['Transition_Camera', 'Transition_Weather_Searching', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/junhyeong/repo/KAIST/제출용/hyperparamter_feature_selection.ipynb 셀 36\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/junhyeong/repo/KAIST/%EC%A0%9C%EC%B6%9C%EC%9A%A9/hyperparamter_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clf \u001b[39m=\u001b[39m XGBClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/junhyeong/repo/KAIST/%EC%A0%9C%EC%B6%9C%EC%9A%A9/hyperparamter_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m shap_df_list, metric_df \u001b[39m=\u001b[39m NestedCVwithOptuna(XBGObjective, clf, \u001b[39m'\u001b[39;49m\u001b[39mxgboost\u001b[39;49m\u001b[39m'\u001b[39;49m)\n","\u001b[1;32m/Users/junhyeong/repo/KAIST/제출용/hyperparamter_feature_selection.ipynb 셀 36\u001b[0m in \u001b[0;36mNestedCVwithOptuna\u001b[0;34m(objective, clf, clf_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/junhyeong/repo/KAIST/%EC%A0%9C%EC%B6%9C%EC%9A%A9/hyperparamter_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Feature Selection을 진행한다\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/junhyeong/repo/KAIST/%EC%A0%9C%EC%B6%9C%EC%9A%A9/hyperparamter_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m selector \u001b[39m=\u001b[39m RFECV(classifier, step\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, cv\u001b[39m=\u001b[39mKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m13\u001b[39m), min_features_to_select\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/junhyeong/repo/KAIST/%EC%A0%9C%EC%B6%9C%EC%9A%A9/hyperparamter_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m selector \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/junhyeong/repo/KAIST/%EC%A0%9C%EC%B6%9C%EC%9A%A9/hyperparamter_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m columns \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/junhyeong/repo/KAIST/%EC%A0%9C%EC%B6%9C%EC%9A%A9/hyperparamter_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m selected_list \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39msupport_\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/strong-design/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py:723\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    720\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    721\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[0;32m--> 723\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    724\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[1;32m    725\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    726\u001b[0m )\n\u001b[1;32m    728\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[1;32m    729\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/strong-design/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py:724\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    720\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    721\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m    723\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m--> 724\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[1;32m    725\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    726\u001b[0m )\n\u001b[1;32m    728\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[1;32m    729\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/strong-design/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py:37\u001b[0m, in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     35\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[1;32m     36\u001b[0m X_test, y_test \u001b[39m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[0;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m rfe\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m     38\u001b[0m     X_train,\n\u001b[1;32m     39\u001b[0m     y_train,\n\u001b[1;32m     40\u001b[0m     \u001b[39mlambda\u001b[39;49;00m estimator, features: _score(\n\u001b[1;32m     41\u001b[0m         estimator, X_test[:, features], y_test, scorer\n\u001b[1;32m     42\u001b[0m     ),\n\u001b[1;32m     43\u001b[0m )\u001b[39m.\u001b[39mscores_\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/strong-design/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py:296\u001b[0m, in \u001b[0;36mRFE._fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    294\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting estimator with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m features.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m np\u001b[39m.\u001b[39msum(support_))\n\u001b[0;32m--> 296\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X[:, features], y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    298\u001b[0m \u001b[39m# Get importance and rank them\u001b[39;00m\n\u001b[1;32m    299\u001b[0m importances \u001b[39m=\u001b[39m _get_feature_importances(\n\u001b[1;32m    300\u001b[0m     estimator,\n\u001b[1;32m    301\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimportance_getter,\n\u001b[1;32m    302\u001b[0m     transform_func\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msquare\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    303\u001b[0m )\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/strong-design/lib/python3.9/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    531\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 532\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/strong-design/lib/python3.9/site-packages/xgboost/sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(\n\u001b[1;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1381\u001b[0m )\n\u001b[1;32m   1382\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1383\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1384\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1397\u001b[0m     enable_categorical\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_categorical,\n\u001b[1;32m   1398\u001b[0m )\n\u001b[0;32m-> 1400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1401\u001b[0m     params,\n\u001b[1;32m   1402\u001b[0m     train_dmatrix,\n\u001b[1;32m   1403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1404\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1405\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1406\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1407\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1408\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1409\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1410\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1411\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1412\u001b[0m )\n\u001b[1;32m   1414\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1415\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/strong-design/lib/python3.9/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    531\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 532\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/strong-design/lib/python3.9/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/strong-design/lib/python3.9/site-packages/xgboost/core.py:1733\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1732\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1733\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1734\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1735\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1736\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1737\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["clf = XGBClassifier(random_state=42)\n","shap_df_list, metric_df = NestedCVwithOptuna(XBGObjective, clf, 'xgboost')"]},{"cell_type":"markdown","metadata":{"id":"lEccKjMAPNvF"},"source":["## 40개의 모델의 개별 performance metric + 평균 performnace metric을 저장한다\n","## 각 모델별 test set의 feature에 따른 shap value를 저장한다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y4Qho7y-PNvF"},"outputs":[],"source":["if label_name == 'three_label':\n","    shap_values_df_0 = pd.concat(shap_df_list[0])\n","    shap_values_df_1 = pd.concat(shap_df_list[1])\n","    shap_values_df_2 = pd.concat(shap_df_list[2])\n","\n","    with pd.ExcelWriter(f\"./xgb_result.xlsx\") as writer:\n","        metric_df.to_excel(writer, sheet_name=\"performance metric\", index=False)\n","        shap_values_df_0.to_excel(writer, sheet_name=\"shap_list_0\", index=False)\n","        shap_values_df_1.to_excel(writer, sheet_name=\"shap_list_1\", index=False)\n","        shap_values_df_2.to_excel(writer, sheet_name=\"shap_list_2\", index=False)\n","\n","if label_name != 'three_label':\n","    shap_values_df = pd.concat(shap_df_list[0])\n","\n","    with pd.ExcelWriter(f\"./xgb_result.xlsx\") as writer:\n","        metric_df.to_excel(writer, sheet_name=\"performance metric\", index=False)\n","        shap_values_df.to_excel(writer, sheet_name=\"shap_list\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"gdKXMCW1PNvF"},"source":["# Random Forest Bayesian"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6YHMp8IFPNvF"},"outputs":[],"source":["class RFObjective(object):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","    \n","    def __call__(self, trial: Trial):\n","        rf_params = {\n","            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n","            'max_depth': trial.suggest_int('max_depth', 3, 10),\n","            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 10),\n","            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n","            'random_state': 42\n","        }\n","\n","        clf = RandomForestClassifier(**rf_params)\n","\n","        mean_accuracy = InnerCrossValidation(clf, self.X, self.y, cv_method, n_fold)\n","\n","        return mean_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhZ9m9ULPNvG","outputId":"acd234e5-dc5d-461a-cdf1-ac56db957847"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_nums :  2\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:01:26,468]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:01:26,815]\u001b[0m Trial 0 finished with value: 0.7863247863247863 and parameters: {'n_estimators': 56, 'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 10}. Best is trial 0 with value: 0.7863247863247863.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7863247863247863\n","Best parameters :  {'n_estimators': 56, 'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 10}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_total_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:01:39,150]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:01:41,278]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 357, 'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 5}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 357, 'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 5}\n","Selected features Num:  26\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_total_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:01:53,184]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:01:54,789]\u001b[0m Trial 0 finished with value: 0.7749287749287749 and parameters: {'n_estimators': 251, 'max_depth': 10, 'min_samples_leaf': 6, 'min_samples_split': 5}. Best is trial 0 with value: 0.7749287749287749.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7749287749287749\n","Best parameters :  {'n_estimators': 251, 'max_depth': 10, 'min_samples_leaf': 6, 'min_samples_split': 5}\n","Selected features Num:  40\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:02:06,618]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:02:08,500]\u001b[0m Trial 0 finished with value: 0.7749287749287749 and parameters: {'n_estimators': 305, 'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 8}. Best is trial 0 with value: 0.7749287749287749.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7749287749287749\n","Best parameters :  {'n_estimators': 305, 'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 8}\n","Selected features Num:  40\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:02:21,015]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:02:21,385]\u001b[0m Trial 0 finished with value: 0.7663817663817664 and parameters: {'n_estimators': 65, 'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 4}. Best is trial 0 with value: 0.7663817663817664.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7663817663817664\n","Best parameters :  {'n_estimators': 65, 'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 4}\n","Selected features Num:  22\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'sms_reply_compeltion_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_max intercharacter time', 'sms_CPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:02:32,729]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:02:34,097]\u001b[0m Trial 0 finished with value: 0.7720797720797721 and parameters: {'n_estimators': 239, 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 2}. Best is trial 0 with value: 0.7720797720797721.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7720797720797721\n","Best parameters :  {'n_estimators': 239, 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 2}\n","Selected features Num:  48\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Receive', 'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:02:46,212]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:02:47,205]\u001b[0m Trial 0 finished with value: 0.7977207977207977 and parameters: {'n_estimators': 176, 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 5}. Best is trial 0 with value: 0.7977207977207977.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7977207977207977\n","Best parameters :  {'n_estimators': 176, 'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 5}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:02:58,788]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:02:59,413]\u001b[0m Trial 0 finished with value: 0.7806267806267806 and parameters: {'n_estimators': 101, 'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 6}. Best is trial 0 with value: 0.7806267806267806.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7806267806267806\n","Best parameters :  {'n_estimators': 101, 'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 6}\n","Selected features Num:  44\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:03:10,691]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:03:11,901]\u001b[0m Trial 0 finished with value: 0.7834757834757835 and parameters: {'n_estimators': 220, 'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 9}. Best is trial 0 with value: 0.7834757834757835.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7834757834757835\n","Best parameters :  {'n_estimators': 220, 'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 9}\n","Selected features Num:  50\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', 'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:03:23,201]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:03:25,061]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 309, 'max_depth': 6, 'min_samples_leaf': 10, 'min_samples_split': 8}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 309, 'max_depth': 6, 'min_samples_leaf': 10, 'min_samples_split': 8}\n","Selected features Num:  50\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', 'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:03:37,168]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:03:39,115]\u001b[0m Trial 0 finished with value: 0.7948717948717948 and parameters: {'n_estimators': 337, 'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 6}. Best is trial 0 with value: 0.7948717948717948.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7948717948717948\n","Best parameters :  {'n_estimators': 337, 'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 6}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:03:51,152]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:03:52,849]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 289, 'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 8}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 289, 'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 8}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_missing_call_time_1', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:04:05,249]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:04:07,397]\u001b[0m Trial 0 finished with value: 0.8034188034188035 and parameters: {'n_estimators': 393, 'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 5}. Best is trial 0 with value: 0.8034188034188035.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8034188034188035\n","Best parameters :  {'n_estimators': 393, 'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 5}\n","Selected features Num:  22\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_screen_unlocking_time', 'phone_register_total_time', 'sms_reply_compeltion_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:04:19,406]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:04:19,761]\u001b[0m Trial 0 finished with value: 0.7863247863247863 and parameters: {'n_estimators': 54, 'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 6}. Best is trial 0 with value: 0.7863247863247863.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7863247863247863\n","Best parameters :  {'n_estimators': 54, 'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 6}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:04:31,762]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:04:32,973]\u001b[0m Trial 0 finished with value: 0.8005698005698005 and parameters: {'n_estimators': 208, 'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 8}. Best is trial 0 with value: 0.8005698005698005.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8005698005698005\n","Best parameters :  {'n_estimators': 208, 'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 8}\n","Selected features Num:  30\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:04:44,926]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:04:46,148]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 211, 'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 5}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 211, 'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 5}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:04:58,055]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:05:00,424]\u001b[0m Trial 0 finished with value: 0.7977207977207977 and parameters: {'n_estimators': 385, 'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 9}. Best is trial 0 with value: 0.7977207977207977.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7977207977207977\n","Best parameters :  {'n_estimators': 385, 'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 9}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:05:12,317]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:05:14,523]\u001b[0m Trial 0 finished with value: 0.7977207977207977 and parameters: {'n_estimators': 373, 'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 2}. Best is trial 0 with value: 0.7977207977207977.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7977207977207977\n","Best parameters :  {'n_estimators': 373, 'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","Selected features Num:  38\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:05:27,099]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:05:28,522]\u001b[0m Trial 0 finished with value: 0.8091168091168092 and parameters: {'n_estimators': 253, 'max_depth': 10, 'min_samples_leaf': 6, 'min_samples_split': 3}. Best is trial 0 with value: 0.8091168091168092.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8091168091168092\n","Best parameters :  {'n_estimators': 253, 'max_depth': 10, 'min_samples_leaf': 6, 'min_samples_split': 3}\n","Selected features Num:  20\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_total_time', 'sms_reply_compeltion_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_CPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_WB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:05:40,989]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:05:42,222]\u001b[0m Trial 0 finished with value: 0.8034188034188035 and parameters: {'n_estimators': 222, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10}. Best is trial 0 with value: 0.8034188034188035.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8034188034188035\n","Best parameters :  {'n_estimators': 222, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10}\n","Selected features Num:  20\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_screen_unlocking_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_CPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:05:53,737]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:05:56,509]\u001b[0m Trial 0 finished with value: 0.8091168091168092 and parameters: {'n_estimators': 420, 'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 6}. Best is trial 0 with value: 0.8091168091168092.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8091168091168092\n","Best parameters :  {'n_estimators': 420, 'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 6}\n","Selected features Num:  44\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:06:08,870]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:06:11,083]\u001b[0m Trial 0 finished with value: 0.7977207977207977 and parameters: {'n_estimators': 386, 'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 6}. Best is trial 0 with value: 0.7977207977207977.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7977207977207977\n","Best parameters :  {'n_estimators': 386, 'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 6}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:06:23,116]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:06:23,524]\u001b[0m Trial 0 finished with value: 0.8148148148148148 and parameters: {'n_estimators': 66, 'max_depth': 10, 'min_samples_leaf': 6, 'min_samples_split': 4}. Best is trial 0 with value: 0.8148148148148148.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8148148148148148\n","Best parameters :  {'n_estimators': 66, 'max_depth': 10, 'min_samples_leaf': 6, 'min_samples_split': 4}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:06:35,322]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:06:38,249]\u001b[0m Trial 0 finished with value: 0.8091168091168092 and parameters: {'n_estimators': 476, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2}. Best is trial 0 with value: 0.8091168091168092.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8091168091168092\n","Best parameters :  {'n_estimators': 476, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_CPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:06:50,737]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:06:51,854]\u001b[0m Trial 0 finished with value: 0.8005698005698005 and parameters: {'n_estimators': 193, 'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 2}. Best is trial 0 with value: 0.8005698005698005.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8005698005698005\n","Best parameters :  {'n_estimators': 193, 'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 2}\n","Selected features Num:  26\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_max intercharacter time', 'sms_CPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:07:03,437]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:07:04,740]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 198, 'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 10}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 198, 'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 10}\n","Selected features Num:  44\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:07:16,390]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:07:18,526]\u001b[0m Trial 0 finished with value: 0.7863247863247863 and parameters: {'n_estimators': 355, 'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 9}. Best is trial 0 with value: 0.7863247863247863.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7863247863247863\n","Best parameters :  {'n_estimators': 355, 'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 9}\n","Selected features Num:  42\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:07:29,894]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:07:32,461]\u001b[0m Trial 0 finished with value: 0.7948717948717948 and parameters: {'n_estimators': 435, 'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 3}. Best is trial 0 with value: 0.7948717948717948.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7948717948717948\n","Best parameters :  {'n_estimators': 435, 'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 3}\n","Selected features Num:  50\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', 'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:07:44,238]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:07:45,262]\u001b[0m Trial 0 finished with value: 0.7863247863247863 and parameters: {'n_estimators': 166, 'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 5}. Best is trial 0 with value: 0.7863247863247863.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7863247863247863\n","Best parameters :  {'n_estimators': 166, 'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 5}\n","Selected features Num:  44\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:07:57,307]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:07:58,649]\u001b[0m Trial 0 finished with value: 0.7834757834757835 and parameters: {'n_estimators': 235, 'max_depth': 7, 'min_samples_leaf': 10, 'min_samples_split': 3}. Best is trial 0 with value: 0.7834757834757835.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7834757834757835\n","Best parameters :  {'n_estimators': 235, 'max_depth': 7, 'min_samples_leaf': 10, 'min_samples_split': 3}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:08:10,987]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:08:12,117]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 224, 'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 224, 'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n","Selected features Num:  24\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_screen_unlocking_time', 'phone_register_total_time', 'sms_reply_compeltion_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_CPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:08:23,582]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:08:24,464]\u001b[0m Trial 0 finished with value: 0.811965811965812 and parameters: {'n_estimators': 142, 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 8}. Best is trial 0 with value: 0.811965811965812.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.811965811965812\n","Best parameters :  {'n_estimators': 142, 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 8}\n","Selected features Num:  44\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:08:35,981]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:08:36,852]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 7}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 132, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","Selected features Num:  44\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:08:48,890]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:08:50,751]\u001b[0m Trial 0 finished with value: 0.7806267806267806 and parameters: {'n_estimators': 327, 'max_depth': 7, 'min_samples_leaf': 10, 'min_samples_split': 4}. Best is trial 0 with value: 0.7806267806267806.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7806267806267806\n","Best parameters :  {'n_estimators': 327, 'max_depth': 7, 'min_samples_leaf': 10, 'min_samples_split': 4}\n","Selected features Num:  30\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_receive_total_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:09:02,144]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:09:03,820]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 267, 'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 3}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 267, 'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 3}\n","Selected features Num:  50\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', 'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:09:15,771]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:09:16,852]\u001b[0m Trial 0 finished with value: 0.7806267806267806 and parameters: {'n_estimators': 159, 'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 9}. Best is trial 0 with value: 0.7806267806267806.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7806267806267806\n","Best parameters :  {'n_estimators': 159, 'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 9}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:09:28,660]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:09:29,163]\u001b[0m Trial 0 finished with value: 0.8091168091168092 and parameters: {'n_estimators': 77, 'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 4}. Best is trial 0 with value: 0.8091168091168092.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8091168091168092\n","Best parameters :  {'n_estimators': 77, 'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 4}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.4444444444444444\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:09:41,093]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:09:41,976]\u001b[0m Trial 0 finished with value: 0.8062678062678063 and parameters: {'n_estimators': 146, 'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 9}. Best is trial 0 with value: 0.8062678062678063.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8062678062678063\n","Best parameters :  {'n_estimators': 146, 'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 9}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:09:53,899]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:09:55,062]\u001b[0m Trial 0 finished with value: 0.7834757834757835 and parameters: {'n_estimators': 202, 'max_depth': 8, 'min_samples_leaf': 10, 'min_samples_split': 3}. Best is trial 0 with value: 0.7834757834757835.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7834757834757835\n","Best parameters :  {'n_estimators': 202, 'max_depth': 8, 'min_samples_leaf': 10, 'min_samples_split': 3}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_missing_call_time_1', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:10:06,891]\u001b[0m A new study created in memory with name: randomforest Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:10:07,646]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 7}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 118, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 7}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_screen_unlocking_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n","\n","mean accuracy :  0.7972222222222225\n","mean precision :  0.7972222222222225\n","mean recall :  0.7395833333333334\n","mean f1 :  0.7185293179043178\n","mean roc_auc :  0.7395833333333334\n","\n"]}],"source":["clf = RandomForestClassifier(random_state=42)\n","shap_df_list, metric_df = NestedCVwithOptuna(RFObjective, clf, 'randomforest')"]},{"cell_type":"markdown","metadata":{"id":"HWVpOJDnPNvG"},"source":["## 40개의 모델의 개별 performance metric + 평균 performnace metric을 저장한다\n","## 각 모델별 test set의 feature에 따른 shap value를 저장한다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIph3XF-PNvG"},"outputs":[],"source":["if label_name == 'three_label':\n","    shap_values_df_0 = pd.concat(shap_df_list[0])\n","    shap_values_df_1 = pd.concat(shap_df_list[1])\n","    shap_values_df_2 = pd.concat(shap_df_list[2])\n","\n","    with pd.ExcelWriter(f\"./rf_result.xlsx\") as writer:\n","        metric_df.to_excel(writer, sheet_name=\"performance metric\", index=False)\n","        shap_values_df_0.to_excel(writer, sheet_name=\"shap_list_0\", index=False)\n","        shap_values_df_1.to_excel(writer, sheet_name=\"shap_list_1\", index=False)\n","        shap_values_df_2.to_excel(writer, sheet_name=\"shap_list_2\", index=False)\n","\n","if label_name != 'three_label':\n","    shap_values_df = pd.concat(shap_df_list[0])\n","\n","    with pd.ExcelWriter(f\"./rf_result.xlsx\") as writer:\n","        metric_df.to_excel(writer, sheet_name=\"performance metric\", index=False)\n","        shap_values_df.to_excel(writer, sheet_name=\"shap_list\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"je1o4WhxPNvG"},"source":["# GBM Bayesian"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FjIiXAIlPNvG"},"outputs":[],"source":["class GBMObjective(object):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","    \n","    def __call__(self, trial: Trial):\n","        gbm_params = {\n","            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n","            'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-3, 1e-1),\n","            'max_depth': trial.suggest_int('max_depth', 3, 10),\n","            'max_features': trial.suggest_categorical('max_features', [None, 'sqrt']),\n","            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 10),\n","            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n","            'subsample': trial.suggest_float('subsample', 0.6, 1.0, step=0.1), \n","            'random_state': 42\n","        }\n","\n","        clf = GradientBoostingClassifier(**gbm_params)\n","\n","        mean_accuracy = InnerCrossValidation(clf, self.X, self.y, cv_method, n_fold)\n","\n","        return mean_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Kiub7n9PNvH","outputId":"019dc9a4-9448-42f6-c301-cf22ea1d9787"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_nums :  2\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:10:31,684]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:10:33,331]\u001b[0m Trial 0 finished with value: 0.8034188034188035 and parameters: {'n_estimators': 119, 'learning_rate': 0.05462078952589598, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 6, 'min_samples_split': 8, 'subsample': 0.8}. Best is trial 0 with value: 0.8034188034188035.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8034188034188035\n","Best parameters :  {'n_estimators': 119, 'learning_rate': 0.05462078952589598, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 6, 'min_samples_split': 8, 'subsample': 0.8}\n","Selected features Num:  20\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_screen_unlocking_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:10:56,707]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:10:56,919]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 56, 'learning_rate': 0.0024899161284824747, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'subsample': 0.7}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 56, 'learning_rate': 0.0024899161284824747, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'subsample': 0.7}\n","Selected features Num:  24\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:11:19,256]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:11:20,575]\u001b[0m Trial 0 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 198, 'learning_rate': 0.004467413467779706, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'subsample': 0.9}. Best is trial 0 with value: 0.7777777777777778.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7777777777777778\n","Best parameters :  {'n_estimators': 198, 'learning_rate': 0.004467413467779706, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'subsample': 0.9}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:11:43,169]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:11:45,461]\u001b[0m Trial 0 finished with value: 0.7150997150997151 and parameters: {'n_estimators': 146, 'learning_rate': 0.0029385940958227543, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 10, 'subsample': 0.8}. Best is trial 0 with value: 0.7150997150997151.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7150997150997151\n","Best parameters :  {'n_estimators': 146, 'learning_rate': 0.0029385940958227543, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 10, 'subsample': 0.8}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:12:07,522]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:12:09,361]\u001b[0m Trial 0 finished with value: 0.7977207977207977 and parameters: {'n_estimators': 232, 'learning_rate': 0.014532125015762435, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 3, 'subsample': 1.0}. Best is trial 0 with value: 0.7977207977207977.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7977207977207977\n","Best parameters :  {'n_estimators': 232, 'learning_rate': 0.014532125015762435, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 3, 'subsample': 1.0}\n","Selected features Num:  42\n","Selected features :  ['transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:12:31,714]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:12:34,429]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 122, 'learning_rate': 0.0019050232799333342, 'max_depth': 6, 'max_features': None, 'min_samples_leaf': 9, 'min_samples_split': 2, 'subsample': 1.0}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 122, 'learning_rate': 0.0019050232799333342, 'max_depth': 6, 'max_features': None, 'min_samples_leaf': 9, 'min_samples_split': 2, 'subsample': 1.0}\n","Selected features Num:  38\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:12:56,742]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:13:02,971]\u001b[0m Trial 0 finished with value: 0.7834757834757835 and parameters: {'n_estimators': 468, 'learning_rate': 0.00977633915688695, 'max_depth': 4, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 10, 'subsample': 0.7}. Best is trial 0 with value: 0.7834757834757835.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7834757834757835\n","Best parameters :  {'n_estimators': 468, 'learning_rate': 0.00977633915688695, 'max_depth': 4, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 10, 'subsample': 0.7}\n","Selected features Num:  40\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:13:25,505]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:13:25,895]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 105, 'learning_rate': 0.002229604024854747, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'subsample': 0.9}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 105, 'learning_rate': 0.002229604024854747, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'subsample': 0.9}\n","Selected features Num:  42\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:13:47,052]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:13:51,494]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 231, 'learning_rate': 0.04916196404535959, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'subsample': 0.6}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 231, 'learning_rate': 0.04916196404535959, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'subsample': 0.6}\n","Selected features Num:  48\n","Selected features :  ['Transition_Phone_Receive', 'Transition_SMS_Reply', 'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:14:13,953]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:14:14,970]\u001b[0m Trial 0 finished with value: 0.8005698005698005 and parameters: {'n_estimators': 126, 'learning_rate': 0.08084784910803584, 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'subsample': 0.8}. Best is trial 0 with value: 0.8005698005698005.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8005698005698005\n","Best parameters :  {'n_estimators': 126, 'learning_rate': 0.08084784910803584, 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'subsample': 0.8}\n","Selected features Num:  40\n","Selected features :  ['Transition_Camera', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:14:38,228]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:14:43,112]\u001b[0m Trial 0 finished with value: 0.8176638176638177 and parameters: {'n_estimators': 417, 'learning_rate': 0.008569856924020838, 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 4, 'subsample': 0.6}. Best is trial 0 with value: 0.8176638176638177.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8176638176638177\n","Best parameters :  {'n_estimators': 417, 'learning_rate': 0.008569856924020838, 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 4, 'subsample': 0.6}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:15:05,253]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:15:05,942]\u001b[0m Trial 0 finished with value: 0.7806267806267806 and parameters: {'n_estimators': 200, 'learning_rate': 0.005572380390797858, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'subsample': 1.0}. Best is trial 0 with value: 0.7806267806267806.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7806267806267806\n","Best parameters :  {'n_estimators': 200, 'learning_rate': 0.005572380390797858, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'subsample': 1.0}\n","Selected features Num:  44\n","Selected features :  ['Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:15:28,851]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:15:29,525]\u001b[0m Trial 0 finished with value: 0.8091168091168092 and parameters: {'n_estimators': 200, 'learning_rate': 0.009941830662077114, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 4, 'subsample': 0.8}. Best is trial 0 with value: 0.8091168091168092.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8091168091168092\n","Best parameters :  {'n_estimators': 200, 'learning_rate': 0.009941830662077114, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 4, 'subsample': 0.8}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:15:52,625]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:15:53,374]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 240, 'learning_rate': 0.07294177463198767, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 9, 'subsample': 1.0}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 240, 'learning_rate': 0.07294177463198767, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 9, 'subsample': 1.0}\n","Selected features Num:  26\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:16:15,480]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:16:22,826]\u001b[0m Trial 0 finished with value: 0.7663817663817664 and parameters: {'n_estimators': 278, 'learning_rate': 0.002037328168021788, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 6, 'min_samples_split': 2, 'subsample': 0.9}. Best is trial 0 with value: 0.7663817663817664.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7663817663817664\n","Best parameters :  {'n_estimators': 278, 'learning_rate': 0.002037328168021788, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 6, 'min_samples_split': 2, 'subsample': 0.9}\n","Selected features Num:  38\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:16:46,190]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:16:46,792]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 99, 'learning_rate': 0.0015437907897842401, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 3, 'subsample': 0.8}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 99, 'learning_rate': 0.0015437907897842401, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 3, 'subsample': 0.8}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:17:09,009]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:17:09,307]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 65, 'learning_rate': 0.0024616715334212125, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 3, 'subsample': 0.7}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6666666666666666\n","Best parameters :  {'n_estimators': 65, 'learning_rate': 0.0024616715334212125, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 3, 'subsample': 0.7}\n","Selected features Num:  38\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:17:31,395]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:17:41,245]\u001b[0m Trial 0 finished with value: 0.7834757834757835 and parameters: {'n_estimators': 496, 'learning_rate': 0.0016237258161311571, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 2, 'subsample': 1.0}. Best is trial 0 with value: 0.7834757834757835.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7834757834757835\n","Best parameters :  {'n_estimators': 496, 'learning_rate': 0.0016237258161311571, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 2, 'subsample': 1.0}\n","Selected features Num:  38\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:18:04,324]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:18:05,347]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 300, 'learning_rate': 0.030272792483420644, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 8, 'subsample': 0.8}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 300, 'learning_rate': 0.030272792483420644, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 8, 'subsample': 0.8}\n","Selected features Num:  42\n","Selected features :  ['transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:18:28,631]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:18:30,283]\u001b[0m Trial 0 finished with value: 0.811965811965812 and parameters: {'n_estimators': 313, 'learning_rate': 0.004756868121955244, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 5, 'subsample': 0.8}. Best is trial 0 with value: 0.811965811965812.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.811965811965812\n","Best parameters :  {'n_estimators': 313, 'learning_rate': 0.004756868121955244, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 5, 'subsample': 0.8}\n","Selected features Num:  24\n","Selected features :  ['average_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_WB']\n","test accuracy :  0.8888888888888888\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:18:51,837]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:18:58,197]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 408, 'learning_rate': 0.04594129497976372, 'max_depth': 6, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 4, 'subsample': 0.6}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 408, 'learning_rate': 0.04594129497976372, 'max_depth': 6, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 4, 'subsample': 0.6}\n","Selected features Num:  46\n","Selected features :  ['Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:19:20,836]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:19:27,186]\u001b[0m Trial 0 finished with value: 0.7720797720797721 and parameters: {'n_estimators': 288, 'learning_rate': 0.004228881685872239, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 6, 'subsample': 0.9}. Best is trial 0 with value: 0.7720797720797721.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7720797720797721\n","Best parameters :  {'n_estimators': 288, 'learning_rate': 0.004228881685872239, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 6, 'subsample': 0.9}\n","Selected features Num:  42\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:19:51,254]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:19:54,476]\u001b[0m Trial 0 finished with value: 0.6723646723646723 and parameters: {'n_estimators': 289, 'learning_rate': 0.0010418147122949579, 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 3, 'subsample': 0.7}. Best is trial 0 with value: 0.6723646723646723.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6723646723646723\n","Best parameters :  {'n_estimators': 289, 'learning_rate': 0.0010418147122949579, 'max_depth': 9, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 3, 'subsample': 0.7}\n","Selected features Num:  24\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:20:17,576]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:20:20,446]\u001b[0m Trial 0 finished with value: 0.6695156695156695 and parameters: {'n_estimators': 199, 'learning_rate': 0.001443821692185672, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 10, 'subsample': 0.8}. Best is trial 0 with value: 0.6695156695156695.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6695156695156695\n","Best parameters :  {'n_estimators': 199, 'learning_rate': 0.001443821692185672, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 10, 'subsample': 0.8}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_WB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:20:42,314]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:20:43,385]\u001b[0m Trial 0 finished with value: 0.7663817663817664 and parameters: {'n_estimators': 183, 'learning_rate': 0.07754923408284936, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 9, 'subsample': 0.9}. Best is trial 0 with value: 0.7663817663817664.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7663817663817664\n","Best parameters :  {'n_estimators': 183, 'learning_rate': 0.07754923408284936, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 9, 'subsample': 0.9}\n","Selected features Num:  44\n","Selected features :  ['Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:21:05,875]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:21:10,614]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 341, 'learning_rate': 0.0027225258339921288, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 3, 'subsample': 0.6}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 341, 'learning_rate': 0.0027225258339921288, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 3, 'subsample': 0.6}\n","Selected features Num:  36\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:21:34,285]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:21:35,679]\u001b[0m Trial 0 finished with value: 0.7977207977207977 and parameters: {'n_estimators': 220, 'learning_rate': 0.06871030942420736, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'subsample': 0.8}. Best is trial 0 with value: 0.7977207977207977.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7977207977207977\n","Best parameters :  {'n_estimators': 220, 'learning_rate': 0.06871030942420736, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'subsample': 0.8}\n","Selected features Num:  30\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:21:57,148]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:21:58,606]\u001b[0m Trial 0 finished with value: 0.7378917378917379 and parameters: {'n_estimators': 193, 'learning_rate': 0.0027326635517735827, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 8, 'subsample': 1.0}. Best is trial 0 with value: 0.7378917378917379.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7378917378917379\n","Best parameters :  {'n_estimators': 193, 'learning_rate': 0.0027326635517735827, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 8, 'subsample': 1.0}\n","Selected features Num:  50\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', 'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:22:23,735]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:22:27,556]\u001b[0m Trial 0 finished with value: 0.792022792022792 and parameters: {'n_estimators': 322, 'learning_rate': 0.06770746850958059, 'max_depth': 4, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 6, 'subsample': 0.8}. Best is trial 0 with value: 0.792022792022792.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.792022792022792\n","Best parameters :  {'n_estimators': 322, 'learning_rate': 0.06770746850958059, 'max_depth': 4, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 6, 'subsample': 0.8}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:22:50,321]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:22:55,495]\u001b[0m Trial 0 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 190, 'learning_rate': 0.049865524082297864, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 10, 'subsample': 0.8}. Best is trial 0 with value: 0.7777777777777778.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7777777777777778\n","Best parameters :  {'n_estimators': 190, 'learning_rate': 0.049865524082297864, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 10, 'subsample': 0.8}\n","Selected features Num:  42\n","Selected features :  ['Transition_Camera', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:23:19,516]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:23:20,853]\u001b[0m Trial 0 finished with value: 0.7977207977207977 and parameters: {'n_estimators': 363, 'learning_rate': 0.011597614013609146, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'subsample': 0.6}. Best is trial 0 with value: 0.7977207977207977.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7977207977207977\n","Best parameters :  {'n_estimators': 363, 'learning_rate': 0.011597614013609146, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'subsample': 0.6}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:23:43,656]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:23:44,521]\u001b[0m Trial 0 finished with value: 0.7150997150997151 and parameters: {'n_estimators': 75, 'learning_rate': 0.005701754806198708, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 2, 'subsample': 0.6}. Best is trial 0 with value: 0.7150997150997151.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7150997150997151\n","Best parameters :  {'n_estimators': 75, 'learning_rate': 0.005701754806198708, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 2, 'subsample': 0.6}\n","Selected features Num:  32\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:24:09,028]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:24:11,179]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 366, 'learning_rate': 0.05291829923439064, 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 8, 'subsample': 0.9}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 366, 'learning_rate': 0.05291829923439064, 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 8, 'subsample': 0.9}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:24:34,052]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:24:41,646]\u001b[0m Trial 0 finished with value: 0.7464387464387464 and parameters: {'n_estimators': 403, 'learning_rate': 0.010775355058293797, 'max_depth': 4, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 9, 'subsample': 1.0}. Best is trial 0 with value: 0.7464387464387464.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7464387464387464\n","Best parameters :  {'n_estimators': 403, 'learning_rate': 0.010775355058293797, 'max_depth': 4, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 9, 'subsample': 1.0}\n","Selected features Num:  34\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:25:05,932]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:25:07,090]\u001b[0m Trial 0 finished with value: 0.7948717948717948 and parameters: {'n_estimators': 260, 'learning_rate': 0.02751009994273288, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'subsample': 0.6}. Best is trial 0 with value: 0.7948717948717948.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7948717948717948\n","Best parameters :  {'n_estimators': 260, 'learning_rate': 0.02751009994273288, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'subsample': 0.6}\n","Selected features Num:  22\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_CPS', 'ws_WB']\n","test accuracy :  0.7777777777777778\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:25:28,582]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:25:30,041]\u001b[0m Trial 0 finished with value: 0.6780626780626781 and parameters: {'n_estimators': 332, 'learning_rate': 0.00117791420967721, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 4, 'subsample': 0.6}. Best is trial 0 with value: 0.6780626780626781.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.6780626780626781\n","Best parameters :  {'n_estimators': 332, 'learning_rate': 0.00117791420967721, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 4, 'subsample': 0.6}\n","Selected features Num:  48\n","Selected features :  ['Transition_Phone_Receive', 'Transition_SMS_Reply', 'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.6666666666666666\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:25:53,824]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:25:57,327]\u001b[0m Trial 0 finished with value: 0.8176638176638177 and parameters: {'n_estimators': 186, 'learning_rate': 0.03990034013674108, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 3, 'subsample': 0.9}. Best is trial 0 with value: 0.8176638176638177.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.8176638176638177\n","Best parameters :  {'n_estimators': 186, 'learning_rate': 0.03990034013674108, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 3, 'subsample': 0.9}\n","Selected features Num:  28\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_total_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_COER', 'sms_TER', 'sms_UB', 'ws_median intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.5555555555555556\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:26:20,875]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:26:23,175]\u001b[0m Trial 0 finished with value: 0.7891737891737892 and parameters: {'n_estimators': 458, 'learning_rate': 0.015315859105493488, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 9, 'subsample': 0.9}. Best is trial 0 with value: 0.7891737891737892.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7891737891737892\n","Best parameters :  {'n_estimators': 458, 'learning_rate': 0.015315859105493488, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 9, 'subsample': 0.9}\n","Selected features Num:  30\n","Selected features :  ['average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'transfer_usage_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_median intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:26:44,507]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:26:49,898]\u001b[0m Trial 0 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 327, 'learning_rate': 0.007448840683867543, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 4, 'subsample': 0.6}. Best is trial 0 with value: 0.7777777777777778.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7777777777777778\n","Best parameters :  {'n_estimators': 327, 'learning_rate': 0.007448840683867543, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 7, 'min_samples_split': 4, 'subsample': 0.6}\n","Selected features Num:  50\n","Selected features :  ['Routine_Screen_Unlock_Pattern', 'Transition_Phone_Register', 'Transition_Phone_Receive', 'Transition_SMS_Reply', 'Transition_Camera', 'Transition_Weather_Searching', 'Transition_Transfer', 'transition_sum_trial', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  1.0\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-08-29 16:27:12,112]\u001b[0m A new study created in memory with name: gbm Study\u001b[0m\n","\u001b[32m[I 2022-08-29 16:27:14,687]\u001b[0m Trial 0 finished with value: 0.7720797720797721 and parameters: {'n_estimators': 194, 'learning_rate': 0.05800095443074267, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 9, 'min_samples_split': 7, 'subsample': 0.6}. Best is trial 0 with value: 0.7720797720797721.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Optuna Best score :  0.7720797720797721\n","Best parameters :  {'n_estimators': 194, 'learning_rate': 0.05800095443074267, 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 9, 'min_samples_split': 7, 'subsample': 0.6}\n","Selected features Num:  44\n","Selected features :  ['Transition_Camera', 'Transition_Weather_Searching', 'average_noti_response_app_start', 'median_noti_response_app_start', 'phone_register_noti_response', 'phone_register_screen_unlocking_time', 'phone_register_phone_number_register_time', 'phone_register_call_time', 'phone_register_total_time', 'phone_receive_total_time', 'phone_receive_missing_call_time_1', 'phone_receive_missing_call_time_2', 'sms_reply_compeltion_time', 'sms_reply_total_time', 'camera_taken_time', 'camera_gallery_delete_time', 'camera_total_time', 'transfer_usage_time', 'transfer_share_time', 'transfer_total_time', 'weather_information_searching_time', 'weather_information_sharing_time', 'weather_searching_total_time', 'sms_average intercharacter time', 'sms_median intercharacter time', 'sms_min intercharacter time', 'sms_max intercharacter time', 'sms_CPS', 'sms_KSPS', 'sms_GPS', 'sms_COER', 'sms_UER', 'sms_TER', 'sms_UB', 'sms_WB', 'ws_average intercharacter time', 'ws_median intercharacter time', 'ws_min intercharacter time', 'ws_max intercharacter time', 'ws_CPS', 'ws_KSPS', 'ws_COER', 'ws_UB', 'ws_WB']\n","test accuracy :  0.7777777777777778\n","\n","mean accuracy :  0.7666666666666669\n","mean precision :  0.7666666666666669\n","mean recall :  0.6875000000000002\n","mean f1 :  0.6458048201798204\n","mean roc_auc :  0.6875000000000002\n","\n"]}],"source":["clf = GradientBoostingClassifier(random_state=42)\n","shap_df_list, metric_df = NestedCVwithOptuna(GBMObjective, clf, 'gbm')"]},{"cell_type":"markdown","metadata":{"id":"vizpjzQDPNvH"},"source":["## 40개의 모델의 개별 performance metric + 평균 performnace metric을 저장한다\n","## 각 모델별 test set의 feature에 따른 shap value를 저장한다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ck93s0HWPNvH"},"outputs":[],"source":["if label_name == 'three_label':\n","    shap_values_df_0 = pd.concat(shap_df_list[0])\n","    shap_values_df_1 = pd.concat(shap_df_list[1])\n","    shap_values_df_2 = pd.concat(shap_df_list[2])\n","\n","    with pd.ExcelWriter(f\"./gbm_result.xlsx\") as writer:\n","        metric_df.to_excel(writer, sheet_name=\"performance metric\", index=False)\n","        shap_values_df_0.to_excel(writer, sheet_name=\"shap_list_0\", index=False)\n","        shap_values_df_1.to_excel(writer, sheet_name=\"shap_list_1\", index=False)\n","        shap_values_df_2.to_excel(writer, sheet_name=\"shap_list_2\", index=False)\n","\n","if label_name != 'three_label':\n","    shap_values_df = pd.concat(shap_df_list[0])\n","\n","    with pd.ExcelWriter(f\"./gbm_result.xlsx\") as writer:\n","        metric_df.to_excel(writer, sheet_name=\"performance metric\", index=False)\n","        shap_values_df.to_excel(writer, sheet_name=\"shap_list\", index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('strong-design')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"3ed2154bd5b5757405c8b05723ca1c1b7d64f46b962974a845269f33b48b03ad"}},"colab":{"name":"hyperparamter_feature_selection.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}